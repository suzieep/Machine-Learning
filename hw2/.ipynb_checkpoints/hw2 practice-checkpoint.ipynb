{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[70, 1, 4, 130, 322, 0, 2, 109, 0, 2.4, 2, 3, 3, 'present'],\n",
       " [67, 0, 3, 115, 564, 0, 2, 160, 0, 1.6, 2, 0, 7, 'absent'],\n",
       " [57, 1, 2, 124, 261, 0, 0, 141, 0, 0.3, 1, 0, 7, 'present'],\n",
       " [64, 1, 4, 128, 263, 0, 0, 105, 1, 0.2, 2, 1, 7, 'absent'],\n",
       " [74, 0, 2, 120, 269, 0, 2, 121, 1, 0.2, 1, 1, 3, 'absent'],\n",
       " [65, 1, 4, 120, 177, 0, 0, 140, 0, 0.4, 1, 0, 7, 'absent'],\n",
       " [56, 1, 3, 130, 256, 1, 2, 142, 1, 0.6, 2, 1, 6, 'present'],\n",
       " [59, 1, 4, 110, 239, 0, 2, 142, 1, 1.2, 2, 1, 7, 'present'],\n",
       " [60, 1, 4, 140, 293, 0, 2, 170, 0, 1.2, 2, 2, 7, 'present'],\n",
       " [63, 0, 4, 150, 407, 0, 2, 154, 0, 4.0, 2, 3, 7, 'present'],\n",
       " [59, 1, 4, 135, 234, 0, 0, 161, 0, 0.5, 2, 0, 7, 'absent'],\n",
       " [53, 1, 4, 142, 226, 0, 2, 111, 1, 0.0, 1, 0, 7, 'absent'],\n",
       " [44, 1, 3, 140, 235, 0, 2, 180, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [61, 1, 1, 134, 234, 0, 0, 145, 0, 2.6, 2, 2, 3, 'present'],\n",
       " [57, 0, 4, 128, 303, 0, 2, 159, 0, 0.0, 1, 1, 3, 'absent'],\n",
       " [71, 0, 4, 112, 149, 0, 0, 125, 0, 1.6, 2, 0, 3, 'absent'],\n",
       " [46, 1, 4, 140, 311, 0, 0, 120, 1, 1.8, 2, 2, 7, 'present'],\n",
       " [53, 1, 4, 140, 203, 1, 2, 155, 1, 3.1, 3, 0, 7, 'present'],\n",
       " [64, 1, 1, 110, 211, 0, 2, 144, 1, 1.8, 2, 0, 3, 'absent'],\n",
       " [40, 1, 1, 140, 199, 0, 0, 178, 1, 1.4, 1, 0, 7, 'absent'],\n",
       " [67, 1, 4, 120, 229, 0, 2, 129, 1, 2.6, 2, 2, 7, 'present'],\n",
       " [48, 1, 2, 130, 245, 0, 2, 180, 0, 0.2, 2, 0, 3, 'absent'],\n",
       " [43, 1, 4, 115, 303, 0, 0, 181, 0, 1.2, 2, 0, 3, 'absent'],\n",
       " [47, 1, 4, 112, 204, 0, 0, 143, 0, 0.1, 1, 0, 3, 'absent'],\n",
       " [54, 0, 2, 132, 288, 1, 2, 159, 1, 0.0, 1, 1, 3, 'absent'],\n",
       " [48, 0, 3, 130, 275, 0, 0, 139, 0, 0.2, 1, 0, 3, 'absent'],\n",
       " [46, 0, 4, 138, 243, 0, 2, 152, 1, 0.0, 2, 0, 3, 'absent'],\n",
       " [51, 0, 3, 120, 295, 0, 2, 157, 0, 0.6, 1, 0, 3, 'absent'],\n",
       " [58, 1, 3, 112, 230, 0, 2, 165, 0, 2.5, 2, 1, 7, 'present'],\n",
       " [71, 0, 3, 110, 265, 1, 2, 130, 0, 0.0, 1, 1, 3, 'absent'],\n",
       " [57, 1, 3, 128, 229, 0, 2, 150, 0, 0.4, 2, 1, 7, 'present'],\n",
       " [66, 1, 4, 160, 228, 0, 2, 138, 0, 2.3, 1, 0, 6, 'absent'],\n",
       " [37, 0, 3, 120, 215, 0, 0, 170, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [59, 1, 4, 170, 326, 0, 2, 140, 1, 3.4, 3, 0, 7, 'present'],\n",
       " [50, 1, 4, 144, 200, 0, 2, 126, 1, 0.9, 2, 0, 7, 'present'],\n",
       " [48, 1, 4, 130, 256, 1, 2, 150, 1, 0.0, 1, 2, 7, 'present'],\n",
       " [61, 1, 4, 140, 207, 0, 2, 138, 1, 1.9, 1, 1, 7, 'present'],\n",
       " [59, 1, 1, 160, 273, 0, 2, 125, 0, 0.0, 1, 0, 3, 'present'],\n",
       " [42, 1, 3, 130, 180, 0, 0, 150, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [48, 1, 4, 122, 222, 0, 2, 186, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [40, 1, 4, 152, 223, 0, 0, 181, 0, 0.0, 1, 0, 7, 'present'],\n",
       " [62, 0, 4, 124, 209, 0, 0, 163, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [44, 1, 3, 130, 233, 0, 0, 179, 1, 0.4, 1, 0, 3, 'absent'],\n",
       " [46, 1, 2, 101, 197, 1, 0, 156, 0, 0.0, 1, 0, 7, 'absent'],\n",
       " [59, 1, 3, 126, 218, 1, 0, 134, 0, 2.2, 2, 1, 6, 'present'],\n",
       " [58, 1, 3, 140, 211, 1, 2, 165, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [49, 1, 3, 118, 149, 0, 2, 126, 0, 0.8, 1, 3, 3, 'present'],\n",
       " [44, 1, 4, 110, 197, 0, 2, 177, 0, 0.0, 1, 1, 3, 'present'],\n",
       " [66, 1, 2, 160, 246, 0, 0, 120, 1, 0.0, 2, 3, 6, 'present'],\n",
       " [65, 0, 4, 150, 225, 0, 2, 114, 0, 1.0, 2, 3, 7, 'present'],\n",
       " [42, 1, 4, 136, 315, 0, 0, 125, 1, 1.8, 2, 0, 6, 'present'],\n",
       " [52, 1, 2, 128, 205, 1, 0, 184, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [65, 0, 3, 140, 417, 1, 2, 157, 0, 0.8, 1, 1, 3, 'absent'],\n",
       " [63, 0, 2, 140, 195, 0, 0, 179, 0, 0.0, 1, 2, 3, 'absent'],\n",
       " [45, 0, 2, 130, 234, 0, 2, 175, 0, 0.6, 2, 0, 3, 'absent'],\n",
       " [41, 0, 2, 105, 198, 0, 0, 168, 0, 0.0, 1, 1, 3, 'absent'],\n",
       " [61, 1, 4, 138, 166, 0, 2, 125, 1, 3.6, 2, 1, 3, 'present'],\n",
       " [60, 0, 3, 120, 178, 1, 0, 96, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [59, 0, 4, 174, 249, 0, 0, 143, 1, 0.0, 2, 0, 3, 'present'],\n",
       " [62, 1, 2, 120, 281, 0, 2, 103, 0, 1.4, 2, 1, 7, 'present'],\n",
       " [57, 1, 3, 150, 126, 1, 0, 173, 0, 0.2, 1, 1, 7, 'absent'],\n",
       " [51, 0, 4, 130, 305, 0, 0, 142, 1, 1.2, 2, 0, 7, 'present'],\n",
       " [44, 1, 3, 120, 226, 0, 0, 169, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [60, 0, 1, 150, 240, 0, 0, 171, 0, 0.9, 1, 0, 3, 'absent'],\n",
       " [63, 1, 1, 145, 233, 1, 2, 150, 0, 2.3, 3, 0, 6, 'absent'],\n",
       " [57, 1, 4, 150, 276, 0, 2, 112, 1, 0.6, 2, 1, 6, 'present'],\n",
       " [51, 1, 4, 140, 261, 0, 2, 186, 1, 0.0, 1, 0, 3, 'absent'],\n",
       " [58, 0, 2, 136, 319, 1, 2, 152, 0, 0.0, 1, 2, 3, 'present'],\n",
       " [44, 0, 3, 118, 242, 0, 0, 149, 0, 0.3, 2, 1, 3, 'absent'],\n",
       " [47, 1, 3, 108, 243, 0, 0, 152, 0, 0.0, 1, 0, 3, 'present'],\n",
       " [61, 1, 4, 120, 260, 0, 0, 140, 1, 3.6, 2, 1, 7, 'present'],\n",
       " [57, 0, 4, 120, 354, 0, 0, 163, 1, 0.6, 1, 0, 3, 'absent'],\n",
       " [70, 1, 2, 156, 245, 0, 2, 143, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [76, 0, 3, 140, 197, 0, 1, 116, 0, 1.1, 2, 0, 3, 'absent'],\n",
       " [67, 0, 4, 106, 223, 0, 0, 142, 0, 0.3, 1, 2, 3, 'absent'],\n",
       " [45, 1, 4, 142, 309, 0, 2, 147, 1, 0.0, 2, 3, 7, 'present'],\n",
       " [45, 1, 4, 104, 208, 0, 2, 148, 1, 3.0, 2, 0, 3, 'absent'],\n",
       " [39, 0, 3, 94, 199, 0, 0, 179, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [42, 0, 3, 120, 209, 0, 0, 173, 0, 0.0, 2, 0, 3, 'absent'],\n",
       " [56, 1, 2, 120, 236, 0, 0, 178, 0, 0.8, 1, 0, 3, 'absent'],\n",
       " [58, 1, 4, 146, 218, 0, 0, 105, 0, 2.0, 2, 1, 7, 'present'],\n",
       " [35, 1, 4, 120, 198, 0, 0, 130, 1, 1.6, 2, 0, 7, 'present'],\n",
       " [58, 1, 4, 150, 270, 0, 2, 111, 1, 0.8, 1, 0, 7, 'present'],\n",
       " [41, 1, 3, 130, 214, 0, 2, 168, 0, 2.0, 2, 0, 3, 'absent'],\n",
       " [57, 1, 4, 110, 201, 0, 0, 126, 1, 1.5, 2, 0, 6, 'absent'],\n",
       " [42, 1, 1, 148, 244, 0, 2, 178, 0, 0.8, 1, 2, 3, 'absent'],\n",
       " [62, 1, 2, 128, 208, 1, 2, 140, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [59, 1, 1, 178, 270, 0, 2, 145, 0, 4.2, 3, 0, 7, 'absent'],\n",
       " [41, 0, 2, 126, 306, 0, 0, 163, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [50, 1, 4, 150, 243, 0, 2, 128, 0, 2.6, 2, 0, 7, 'present'],\n",
       " [59, 1, 2, 140, 221, 0, 0, 164, 1, 0.0, 1, 0, 3, 'absent'],\n",
       " [61, 0, 4, 130, 330, 0, 2, 169, 0, 0.0, 1, 0, 3, 'present'],\n",
       " [54, 1, 4, 124, 266, 0, 2, 109, 1, 2.2, 2, 1, 7, 'present'],\n",
       " [54, 1, 4, 110, 206, 0, 2, 108, 1, 0.0, 2, 1, 3, 'present'],\n",
       " [52, 1, 4, 125, 212, 0, 0, 168, 0, 1.0, 1, 2, 7, 'present'],\n",
       " [47, 1, 4, 110, 275, 0, 2, 118, 1, 1.0, 2, 1, 3, 'present'],\n",
       " [66, 1, 4, 120, 302, 0, 2, 151, 0, 0.4, 2, 0, 3, 'absent'],\n",
       " [58, 1, 4, 100, 234, 0, 0, 156, 0, 0.1, 1, 1, 7, 'present'],\n",
       " [64, 0, 3, 140, 313, 0, 0, 133, 0, 0.2, 1, 0, 7, 'absent'],\n",
       " [50, 0, 2, 120, 244, 0, 0, 162, 0, 1.1, 1, 0, 3, 'absent'],\n",
       " [44, 0, 3, 108, 141, 0, 0, 175, 0, 0.6, 2, 0, 3, 'absent'],\n",
       " [67, 1, 4, 120, 237, 0, 0, 71, 0, 1.0, 2, 0, 3, 'present'],\n",
       " [49, 0, 4, 130, 269, 0, 0, 163, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [57, 1, 4, 165, 289, 1, 2, 124, 0, 1.0, 2, 3, 7, 'present'],\n",
       " [63, 1, 4, 130, 254, 0, 2, 147, 0, 1.4, 2, 1, 7, 'present'],\n",
       " [48, 1, 4, 124, 274, 0, 2, 166, 0, 0.5, 2, 0, 7, 'present'],\n",
       " [51, 1, 3, 100, 222, 0, 0, 143, 1, 1.2, 2, 0, 3, 'absent'],\n",
       " [60, 0, 4, 150, 258, 0, 2, 157, 0, 2.6, 2, 2, 7, 'present'],\n",
       " [59, 1, 4, 140, 177, 0, 0, 162, 1, 0.0, 1, 1, 7, 'present'],\n",
       " [45, 0, 2, 112, 160, 0, 0, 138, 0, 0.0, 2, 0, 3, 'absent'],\n",
       " [55, 0, 4, 180, 327, 0, 1, 117, 1, 3.4, 2, 0, 3, 'present'],\n",
       " [41, 1, 2, 110, 235, 0, 0, 153, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [60, 0, 4, 158, 305, 0, 2, 161, 0, 0.0, 1, 0, 3, 'present'],\n",
       " [54, 0, 3, 135, 304, 1, 0, 170, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [42, 1, 2, 120, 295, 0, 0, 162, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [49, 0, 2, 134, 271, 0, 0, 162, 0, 0.0, 2, 0, 3, 'absent'],\n",
       " [46, 1, 4, 120, 249, 0, 2, 144, 0, 0.8, 1, 0, 7, 'present'],\n",
       " [56, 0, 4, 200, 288, 1, 2, 133, 1, 4.0, 3, 2, 7, 'present'],\n",
       " [66, 0, 1, 150, 226, 0, 0, 114, 0, 2.6, 3, 0, 3, 'absent'],\n",
       " [56, 1, 4, 130, 283, 1, 2, 103, 1, 1.6, 3, 0, 7, 'present'],\n",
       " [49, 1, 3, 120, 188, 0, 0, 139, 0, 2.0, 2, 3, 7, 'present'],\n",
       " [54, 1, 4, 122, 286, 0, 2, 116, 1, 3.2, 2, 2, 3, 'present'],\n",
       " [57, 1, 4, 152, 274, 0, 0, 88, 1, 1.2, 2, 1, 7, 'present'],\n",
       " [65, 0, 3, 160, 360, 0, 2, 151, 0, 0.8, 1, 0, 3, 'absent'],\n",
       " [54, 1, 3, 125, 273, 0, 2, 152, 0, 0.5, 3, 1, 3, 'absent'],\n",
       " [54, 0, 3, 160, 201, 0, 0, 163, 0, 0.0, 1, 1, 3, 'absent'],\n",
       " [62, 1, 4, 120, 267, 0, 0, 99, 1, 1.8, 2, 2, 7, 'present'],\n",
       " [52, 0, 3, 136, 196, 0, 2, 169, 0, 0.1, 2, 0, 3, 'absent'],\n",
       " [52, 1, 2, 134, 201, 0, 0, 158, 0, 0.8, 1, 1, 3, 'absent'],\n",
       " [60, 1, 4, 117, 230, 1, 0, 160, 1, 1.4, 1, 2, 7, 'present'],\n",
       " [63, 0, 4, 108, 269, 0, 0, 169, 1, 1.8, 2, 2, 3, 'present'],\n",
       " [66, 1, 4, 112, 212, 0, 2, 132, 1, 0.1, 1, 1, 3, 'present'],\n",
       " [42, 1, 4, 140, 226, 0, 0, 178, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [64, 1, 4, 120, 246, 0, 2, 96, 1, 2.2, 3, 1, 3, 'present'],\n",
       " [54, 1, 3, 150, 232, 0, 2, 165, 0, 1.6, 1, 0, 7, 'absent'],\n",
       " [46, 0, 3, 142, 177, 0, 2, 160, 1, 1.4, 3, 0, 3, 'absent'],\n",
       " [67, 0, 3, 152, 277, 0, 0, 172, 0, 0.0, 1, 1, 3, 'absent'],\n",
       " [56, 1, 4, 125, 249, 1, 2, 144, 1, 1.2, 2, 1, 3, 'present'],\n",
       " [34, 0, 2, 118, 210, 0, 0, 192, 0, 0.7, 1, 0, 3, 'absent'],\n",
       " [57, 1, 4, 132, 207, 0, 0, 168, 1, 0.0, 1, 0, 7, 'absent'],\n",
       " [64, 1, 4, 145, 212, 0, 2, 132, 0, 2.0, 2, 2, 6, 'present'],\n",
       " [59, 1, 4, 138, 271, 0, 2, 182, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [50, 1, 3, 140, 233, 0, 0, 163, 0, 0.6, 2, 1, 7, 'present'],\n",
       " [51, 1, 1, 125, 213, 0, 2, 125, 1, 1.4, 1, 1, 3, 'absent'],\n",
       " [54, 1, 2, 192, 283, 0, 2, 195, 0, 0.0, 1, 1, 7, 'present'],\n",
       " [53, 1, 4, 123, 282, 0, 0, 95, 1, 2.0, 2, 2, 7, 'present'],\n",
       " [52, 1, 4, 112, 230, 0, 0, 160, 0, 0.0, 1, 1, 3, 'present'],\n",
       " [40, 1, 4, 110, 167, 0, 2, 114, 1, 2.0, 2, 0, 7, 'present'],\n",
       " [58, 1, 3, 132, 224, 0, 2, 173, 0, 3.2, 1, 2, 7, 'present'],\n",
       " [41, 0, 3, 112, 268, 0, 2, 172, 1, 0.0, 1, 0, 3, 'absent'],\n",
       " [41, 1, 3, 112, 250, 0, 0, 179, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [50, 0, 3, 120, 219, 0, 0, 158, 0, 1.6, 2, 0, 3, 'absent'],\n",
       " [54, 0, 3, 108, 267, 0, 2, 167, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [64, 0, 4, 130, 303, 0, 0, 122, 0, 2.0, 2, 2, 3, 'absent'],\n",
       " [51, 0, 3, 130, 256, 0, 2, 149, 0, 0.5, 1, 0, 3, 'absent'],\n",
       " [46, 0, 2, 105, 204, 0, 0, 172, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [55, 1, 4, 140, 217, 0, 0, 111, 1, 5.6, 3, 0, 7, 'present'],\n",
       " [45, 1, 2, 128, 308, 0, 2, 170, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [56, 1, 1, 120, 193, 0, 2, 162, 0, 1.9, 2, 0, 7, 'absent'],\n",
       " [66, 0, 4, 178, 228, 1, 0, 165, 1, 1.0, 2, 2, 7, 'present'],\n",
       " [38, 1, 1, 120, 231, 0, 0, 182, 1, 3.8, 2, 0, 7, 'present'],\n",
       " [62, 0, 4, 150, 244, 0, 0, 154, 1, 1.4, 2, 0, 3, 'present'],\n",
       " [55, 1, 2, 130, 262, 0, 0, 155, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [58, 1, 4, 128, 259, 0, 2, 130, 1, 3.0, 2, 2, 7, 'present'],\n",
       " [43, 1, 4, 110, 211, 0, 0, 161, 0, 0.0, 1, 0, 7, 'absent'],\n",
       " [64, 0, 4, 180, 325, 0, 0, 154, 1, 0.0, 1, 0, 3, 'absent'],\n",
       " [50, 0, 4, 110, 254, 0, 2, 159, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [53, 1, 3, 130, 197, 1, 2, 152, 0, 1.2, 3, 0, 3, 'absent'],\n",
       " [45, 0, 4, 138, 236, 0, 2, 152, 1, 0.2, 2, 0, 3, 'absent'],\n",
       " [65, 1, 1, 138, 282, 1, 2, 174, 0, 1.4, 2, 1, 3, 'present'],\n",
       " [69, 1, 1, 160, 234, 1, 2, 131, 0, 0.1, 2, 1, 3, 'absent'],\n",
       " [69, 1, 3, 140, 254, 0, 2, 146, 0, 2.0, 2, 3, 7, 'present'],\n",
       " [67, 1, 4, 100, 299, 0, 2, 125, 1, 0.9, 2, 2, 3, 'present'],\n",
       " [68, 0, 3, 120, 211, 0, 2, 115, 0, 1.5, 2, 0, 3, 'absent'],\n",
       " [34, 1, 1, 118, 182, 0, 2, 174, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [62, 0, 4, 138, 294, 1, 0, 106, 0, 1.9, 2, 3, 3, 'present'],\n",
       " [51, 1, 4, 140, 298, 0, 0, 122, 1, 4.2, 2, 3, 7, 'present'],\n",
       " [46, 1, 3, 150, 231, 0, 0, 147, 0, 3.6, 2, 0, 3, 'present'],\n",
       " [67, 1, 4, 125, 254, 1, 0, 163, 0, 0.2, 2, 2, 7, 'present'],\n",
       " [50, 1, 3, 129, 196, 0, 0, 163, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [42, 1, 3, 120, 240, 1, 0, 194, 0, 0.8, 3, 0, 7, 'absent'],\n",
       " [56, 0, 4, 134, 409, 0, 2, 150, 1, 1.9, 2, 2, 7, 'present'],\n",
       " [41, 1, 4, 110, 172, 0, 2, 158, 0, 0.0, 1, 0, 7, 'present'],\n",
       " [42, 0, 4, 102, 265, 0, 2, 122, 0, 0.6, 2, 0, 3, 'absent'],\n",
       " [53, 1, 3, 130, 246, 1, 2, 173, 0, 0.0, 1, 3, 3, 'absent'],\n",
       " [43, 1, 3, 130, 315, 0, 0, 162, 0, 1.9, 1, 1, 3, 'absent'],\n",
       " [56, 1, 4, 132, 184, 0, 2, 105, 1, 2.1, 2, 1, 6, 'present'],\n",
       " [52, 1, 4, 108, 233, 1, 0, 147, 0, 0.1, 1, 3, 7, 'absent'],\n",
       " [62, 0, 4, 140, 394, 0, 2, 157, 0, 1.2, 2, 0, 3, 'absent'],\n",
       " [70, 1, 3, 160, 269, 0, 0, 112, 1, 2.9, 2, 1, 7, 'present'],\n",
       " [54, 1, 4, 140, 239, 0, 0, 160, 0, 1.2, 1, 0, 3, 'absent'],\n",
       " [70, 1, 4, 145, 174, 0, 0, 125, 1, 2.6, 3, 0, 7, 'present'],\n",
       " [54, 1, 2, 108, 309, 0, 0, 156, 0, 0.0, 1, 0, 7, 'absent'],\n",
       " [35, 1, 4, 126, 282, 0, 2, 156, 1, 0.0, 1, 0, 7, 'present'],\n",
       " [48, 1, 3, 124, 255, 1, 0, 175, 0, 0.0, 1, 2, 3, 'absent'],\n",
       " [55, 0, 2, 135, 250, 0, 2, 161, 0, 1.4, 2, 0, 3, 'absent'],\n",
       " [58, 0, 4, 100, 248, 0, 2, 122, 0, 1.0, 2, 0, 3, 'absent'],\n",
       " [54, 0, 3, 110, 214, 0, 0, 158, 0, 1.6, 2, 0, 3, 'absent'],\n",
       " [69, 0, 1, 140, 239, 0, 0, 151, 0, 1.8, 1, 2, 3, 'absent'],\n",
       " [77, 1, 4, 125, 304, 0, 2, 162, 1, 0.0, 1, 3, 3, 'present'],\n",
       " [68, 1, 3, 118, 277, 0, 0, 151, 0, 1.0, 1, 1, 7, 'absent'],\n",
       " [58, 1, 4, 125, 300, 0, 2, 171, 0, 0.0, 1, 2, 7, 'present'],\n",
       " [60, 1, 4, 125, 258, 0, 2, 141, 1, 2.8, 2, 1, 7, 'present'],\n",
       " [51, 1, 4, 140, 299, 0, 0, 173, 1, 1.6, 1, 0, 7, 'present'],\n",
       " [55, 1, 4, 160, 289, 0, 2, 145, 1, 0.8, 2, 1, 7, 'present'],\n",
       " [52, 1, 1, 152, 298, 1, 0, 178, 0, 1.2, 2, 0, 7, 'absent'],\n",
       " [60, 0, 3, 102, 318, 0, 0, 160, 0, 0.0, 1, 1, 3, 'absent'],\n",
       " [58, 1, 3, 105, 240, 0, 2, 154, 1, 0.6, 2, 0, 7, 'absent'],\n",
       " [64, 1, 3, 125, 309, 0, 0, 131, 1, 1.8, 2, 0, 7, 'present'],\n",
       " [37, 1, 3, 130, 250, 0, 0, 187, 0, 3.5, 3, 0, 3, 'absent'],\n",
       " [59, 1, 1, 170, 288, 0, 2, 159, 0, 0.2, 2, 0, 7, 'present'],\n",
       " [51, 1, 3, 125, 245, 1, 2, 166, 0, 2.4, 2, 0, 3, 'absent'],\n",
       " [43, 0, 3, 122, 213, 0, 0, 165, 0, 0.2, 2, 0, 3, 'absent'],\n",
       " [58, 1, 4, 128, 216, 0, 2, 131, 1, 2.2, 2, 3, 7, 'present'],\n",
       " [29, 1, 2, 130, 204, 0, 2, 202, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [41, 0, 2, 130, 204, 0, 2, 172, 0, 1.4, 1, 0, 3, 'absent'],\n",
       " [63, 0, 3, 135, 252, 0, 2, 172, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [51, 1, 3, 94, 227, 0, 0, 154, 1, 0.0, 1, 1, 7, 'absent'],\n",
       " [54, 1, 3, 120, 258, 0, 2, 147, 0, 0.4, 2, 0, 7, 'absent'],\n",
       " [44, 1, 2, 120, 220, 0, 0, 170, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [54, 1, 4, 110, 239, 0, 0, 126, 1, 2.8, 2, 1, 7, 'present'],\n",
       " [65, 1, 4, 135, 254, 0, 2, 127, 0, 2.8, 2, 1, 7, 'present'],\n",
       " [57, 1, 3, 150, 168, 0, 0, 174, 0, 1.6, 1, 0, 3, 'absent'],\n",
       " [63, 1, 4, 130, 330, 1, 2, 132, 1, 1.8, 1, 3, 7, 'present'],\n",
       " [35, 0, 4, 138, 183, 0, 0, 182, 0, 1.4, 1, 0, 3, 'absent'],\n",
       " [41, 1, 2, 135, 203, 0, 0, 132, 0, 0.0, 2, 0, 6, 'absent'],\n",
       " [62, 0, 3, 130, 263, 0, 0, 97, 0, 1.2, 2, 1, 7, 'present'],\n",
       " [43, 0, 4, 132, 341, 1, 2, 136, 1, 3.0, 2, 0, 7, 'present'],\n",
       " [58, 0, 1, 150, 283, 1, 2, 162, 0, 1.0, 1, 0, 3, 'absent'],\n",
       " [52, 1, 1, 118, 186, 0, 2, 190, 0, 0.0, 2, 0, 6, 'absent'],\n",
       " [61, 0, 4, 145, 307, 0, 2, 146, 1, 1.0, 2, 0, 7, 'present'],\n",
       " [39, 1, 4, 118, 219, 0, 0, 140, 0, 1.2, 2, 0, 7, 'present'],\n",
       " [45, 1, 4, 115, 260, 0, 2, 185, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [52, 1, 4, 128, 255, 0, 0, 161, 1, 0.0, 1, 1, 7, 'present'],\n",
       " [62, 1, 3, 130, 231, 0, 0, 146, 0, 1.8, 2, 3, 7, 'absent'],\n",
       " [62, 0, 4, 160, 164, 0, 2, 145, 0, 6.2, 3, 3, 7, 'present'],\n",
       " [53, 0, 4, 138, 234, 0, 2, 160, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [43, 1, 4, 120, 177, 0, 2, 120, 1, 2.5, 2, 0, 7, 'present'],\n",
       " [47, 1, 3, 138, 257, 0, 2, 156, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [52, 1, 2, 120, 325, 0, 0, 172, 0, 0.2, 1, 0, 3, 'absent'],\n",
       " [68, 1, 3, 180, 274, 1, 2, 150, 1, 1.6, 2, 0, 7, 'present'],\n",
       " [39, 1, 3, 140, 321, 0, 2, 182, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [53, 0, 4, 130, 264, 0, 2, 143, 0, 0.4, 2, 0, 3, 'absent'],\n",
       " [62, 0, 4, 140, 268, 0, 2, 160, 0, 3.6, 3, 2, 3, 'present'],\n",
       " [51, 0, 3, 140, 308, 0, 2, 142, 0, 1.5, 1, 1, 3, 'absent'],\n",
       " [60, 1, 4, 130, 253, 0, 0, 144, 1, 1.4, 1, 1, 7, 'present'],\n",
       " [65, 1, 4, 110, 248, 0, 2, 158, 0, 0.6, 1, 2, 6, 'present'],\n",
       " [65, 0, 3, 155, 269, 0, 0, 148, 0, 0.8, 1, 0, 3, 'absent'],\n",
       " [60, 1, 3, 140, 185, 0, 2, 155, 0, 3.0, 2, 0, 3, 'present'],\n",
       " [60, 1, 4, 145, 282, 0, 2, 142, 1, 2.8, 2, 2, 7, 'present'],\n",
       " [54, 1, 4, 120, 188, 0, 0, 113, 0, 1.4, 2, 1, 7, 'present'],\n",
       " [44, 1, 2, 130, 219, 0, 2, 188, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [44, 1, 4, 112, 290, 0, 2, 153, 0, 0.0, 1, 1, 3, 'present'],\n",
       " [51, 1, 3, 110, 175, 0, 0, 123, 0, 0.6, 1, 0, 3, 'absent'],\n",
       " [59, 1, 3, 150, 212, 1, 0, 157, 0, 1.6, 1, 0, 3, 'absent'],\n",
       " [71, 0, 2, 160, 302, 0, 0, 162, 0, 0.4, 1, 2, 3, 'absent'],\n",
       " [61, 1, 3, 150, 243, 1, 0, 137, 1, 1.0, 2, 0, 3, 'absent'],\n",
       " [55, 1, 4, 132, 353, 0, 0, 132, 1, 1.2, 2, 1, 7, 'present'],\n",
       " [64, 1, 3, 140, 335, 0, 0, 158, 0, 0.0, 1, 0, 3, 'present'],\n",
       " [43, 1, 4, 150, 247, 0, 0, 171, 0, 1.5, 1, 0, 3, 'absent'],\n",
       " [58, 0, 3, 120, 340, 0, 0, 172, 0, 0.0, 1, 0, 3, 'absent'],\n",
       " [60, 1, 4, 130, 206, 0, 2, 132, 1, 2.4, 2, 2, 7, 'present'],\n",
       " [58, 1, 2, 120, 284, 0, 2, 160, 0, 1.8, 2, 0, 3, 'present'],\n",
       " [49, 1, 2, 130, 266, 0, 0, 171, 0, 0.6, 1, 0, 3, 'absent'],\n",
       " [48, 1, 2, 110, 229, 0, 0, 168, 0, 1.0, 3, 0, 7, 'present'],\n",
       " [52, 1, 3, 172, 199, 1, 0, 162, 0, 0.5, 1, 0, 7, 'absent'],\n",
       " [44, 1, 2, 120, 263, 0, 0, 173, 0, 0.0, 1, 0, 7, 'absent'],\n",
       " [56, 0, 2, 140, 294, 0, 2, 153, 0, 1.3, 2, 0, 3, 'absent'],\n",
       " [57, 1, 4, 140, 192, 0, 0, 148, 0, 0.4, 2, 0, 6, 'absent'],\n",
       " [67, 1, 4, 160, 286, 0, 2, 108, 1, 1.5, 2, 3, 3, 'present']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "filename = '/Users/soojinlee/python/hw2/heart-statlog.csv'\n",
    "names = ['id','age','sex','chest','resting_blood_pressure','serum_cholestoral','fasting_blood_sugar','resting_electrocardiographic_results','maximum_heart_rate_achieved','exercise_induced_angina','oldpeak','slope','number_of_major_vessels','thal','class']\n",
    "data = read_csv(filename)#,names=names)\n",
    "\n",
    "a_list = data.values\n",
    "a_list = a_list.tolist()\n",
    "aa_list=[]\n",
    "\n",
    "for i in range(len(a_list)):\n",
    "    temp=[]\n",
    "    for j in range(1,len(a_list[0])):\n",
    "        temp.append(a_list[i][j])\n",
    "    aa_list.append(temp)\n",
    "a_list=aa_list\n",
    "\n",
    "a_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c'], dtype='<U1')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-A 1)\n",
    "def uniq_values(in_list):\n",
    "    result = set(in_list)\n",
    "    result = list(result)\n",
    "    result.sort()\n",
    "    return result\n",
    "import numpy as np \n",
    "  \n",
    "# function to get unique values \n",
    "def unique(inlist): \n",
    "    x = np.array(inlist) \n",
    "    return np.unique(x)\n",
    "\n",
    "unique(['a','a','b','b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{29: 0,\n",
       "  34: 1,\n",
       "  35: 2,\n",
       "  37: 3,\n",
       "  38: 4,\n",
       "  39: 5,\n",
       "  40: 6,\n",
       "  41: 7,\n",
       "  42: 8,\n",
       "  43: 9,\n",
       "  44: 10,\n",
       "  45: 11,\n",
       "  46: 12,\n",
       "  47: 13,\n",
       "  48: 14,\n",
       "  49: 15,\n",
       "  50: 16,\n",
       "  51: 17,\n",
       "  52: 18,\n",
       "  53: 19,\n",
       "  54: 20,\n",
       "  55: 21,\n",
       "  56: 22,\n",
       "  57: 23,\n",
       "  58: 24,\n",
       "  59: 25,\n",
       "  60: 26,\n",
       "  61: 27,\n",
       "  62: 28,\n",
       "  63: 29,\n",
       "  64: 30,\n",
       "  65: 31,\n",
       "  66: 32,\n",
       "  67: 33,\n",
       "  68: 34,\n",
       "  69: 35,\n",
       "  70: 36,\n",
       "  71: 37,\n",
       "  74: 38,\n",
       "  76: 39,\n",
       "  77: 40},\n",
       " {0: 0, 1: 1},\n",
       " {1: 0, 2: 1, 3: 2, 4: 3},\n",
       " {94: 0,\n",
       "  100: 1,\n",
       "  101: 2,\n",
       "  102: 3,\n",
       "  104: 4,\n",
       "  105: 5,\n",
       "  106: 6,\n",
       "  108: 7,\n",
       "  110: 8,\n",
       "  112: 9,\n",
       "  115: 10,\n",
       "  117: 11,\n",
       "  118: 12,\n",
       "  120: 13,\n",
       "  122: 14,\n",
       "  123: 15,\n",
       "  124: 16,\n",
       "  125: 17,\n",
       "  126: 18,\n",
       "  128: 19,\n",
       "  129: 20,\n",
       "  130: 21,\n",
       "  132: 22,\n",
       "  134: 23,\n",
       "  135: 24,\n",
       "  136: 25,\n",
       "  138: 26,\n",
       "  140: 27,\n",
       "  142: 28,\n",
       "  144: 29,\n",
       "  145: 30,\n",
       "  146: 31,\n",
       "  148: 32,\n",
       "  150: 33,\n",
       "  152: 34,\n",
       "  155: 35,\n",
       "  156: 36,\n",
       "  158: 37,\n",
       "  160: 38,\n",
       "  165: 39,\n",
       "  170: 40,\n",
       "  172: 41,\n",
       "  174: 42,\n",
       "  178: 43,\n",
       "  180: 44,\n",
       "  192: 45,\n",
       "  200: 46},\n",
       " {126: 0,\n",
       "  141: 1,\n",
       "  149: 2,\n",
       "  160: 3,\n",
       "  164: 4,\n",
       "  166: 5,\n",
       "  167: 6,\n",
       "  168: 7,\n",
       "  172: 8,\n",
       "  174: 9,\n",
       "  175: 10,\n",
       "  177: 11,\n",
       "  178: 12,\n",
       "  180: 13,\n",
       "  182: 14,\n",
       "  183: 15,\n",
       "  184: 16,\n",
       "  185: 17,\n",
       "  186: 18,\n",
       "  188: 19,\n",
       "  192: 20,\n",
       "  193: 21,\n",
       "  195: 22,\n",
       "  196: 23,\n",
       "  197: 24,\n",
       "  198: 25,\n",
       "  199: 26,\n",
       "  200: 27,\n",
       "  201: 28,\n",
       "  203: 29,\n",
       "  204: 30,\n",
       "  205: 31,\n",
       "  206: 32,\n",
       "  207: 33,\n",
       "  208: 34,\n",
       "  209: 35,\n",
       "  210: 36,\n",
       "  211: 37,\n",
       "  212: 38,\n",
       "  213: 39,\n",
       "  214: 40,\n",
       "  215: 41,\n",
       "  216: 42,\n",
       "  217: 43,\n",
       "  218: 44,\n",
       "  219: 45,\n",
       "  220: 46,\n",
       "  221: 47,\n",
       "  222: 48,\n",
       "  223: 49,\n",
       "  224: 50,\n",
       "  225: 51,\n",
       "  226: 52,\n",
       "  227: 53,\n",
       "  228: 54,\n",
       "  229: 55,\n",
       "  230: 56,\n",
       "  231: 57,\n",
       "  232: 58,\n",
       "  233: 59,\n",
       "  234: 60,\n",
       "  235: 61,\n",
       "  236: 62,\n",
       "  237: 63,\n",
       "  239: 64,\n",
       "  240: 65,\n",
       "  242: 66,\n",
       "  243: 67,\n",
       "  244: 68,\n",
       "  245: 69,\n",
       "  246: 70,\n",
       "  247: 71,\n",
       "  248: 72,\n",
       "  249: 73,\n",
       "  250: 74,\n",
       "  252: 75,\n",
       "  253: 76,\n",
       "  254: 77,\n",
       "  255: 78,\n",
       "  256: 79,\n",
       "  257: 80,\n",
       "  258: 81,\n",
       "  259: 82,\n",
       "  260: 83,\n",
       "  261: 84,\n",
       "  262: 85,\n",
       "  263: 86,\n",
       "  264: 87,\n",
       "  265: 88,\n",
       "  266: 89,\n",
       "  267: 90,\n",
       "  268: 91,\n",
       "  269: 92,\n",
       "  270: 93,\n",
       "  271: 94,\n",
       "  273: 95,\n",
       "  274: 96,\n",
       "  275: 97,\n",
       "  276: 98,\n",
       "  277: 99,\n",
       "  281: 100,\n",
       "  282: 101,\n",
       "  283: 102,\n",
       "  284: 103,\n",
       "  286: 104,\n",
       "  288: 105,\n",
       "  289: 106,\n",
       "  290: 107,\n",
       "  293: 108,\n",
       "  294: 109,\n",
       "  295: 110,\n",
       "  298: 111,\n",
       "  299: 112,\n",
       "  300: 113,\n",
       "  302: 114,\n",
       "  303: 115,\n",
       "  304: 116,\n",
       "  305: 117,\n",
       "  306: 118,\n",
       "  307: 119,\n",
       "  308: 120,\n",
       "  309: 121,\n",
       "  311: 122,\n",
       "  313: 123,\n",
       "  315: 124,\n",
       "  318: 125,\n",
       "  319: 126,\n",
       "  321: 127,\n",
       "  322: 128,\n",
       "  325: 129,\n",
       "  326: 130,\n",
       "  327: 131,\n",
       "  330: 132,\n",
       "  335: 133,\n",
       "  340: 134,\n",
       "  341: 135,\n",
       "  353: 136,\n",
       "  354: 137,\n",
       "  360: 138,\n",
       "  394: 139,\n",
       "  407: 140,\n",
       "  409: 141,\n",
       "  417: 142,\n",
       "  564: 143},\n",
       " {0: 0, 1: 1},\n",
       " {0: 0, 1: 1, 2: 2},\n",
       " {71: 0,\n",
       "  88: 1,\n",
       "  95: 2,\n",
       "  96: 3,\n",
       "  97: 4,\n",
       "  99: 5,\n",
       "  103: 6,\n",
       "  105: 7,\n",
       "  106: 8,\n",
       "  108: 9,\n",
       "  109: 10,\n",
       "  111: 11,\n",
       "  112: 12,\n",
       "  113: 13,\n",
       "  114: 14,\n",
       "  115: 15,\n",
       "  116: 16,\n",
       "  117: 17,\n",
       "  118: 18,\n",
       "  120: 19,\n",
       "  121: 20,\n",
       "  122: 21,\n",
       "  123: 22,\n",
       "  124: 23,\n",
       "  125: 24,\n",
       "  126: 25,\n",
       "  127: 26,\n",
       "  128: 27,\n",
       "  129: 28,\n",
       "  130: 29,\n",
       "  131: 30,\n",
       "  132: 31,\n",
       "  133: 32,\n",
       "  134: 33,\n",
       "  136: 34,\n",
       "  137: 35,\n",
       "  138: 36,\n",
       "  139: 37,\n",
       "  140: 38,\n",
       "  141: 39,\n",
       "  142: 40,\n",
       "  143: 41,\n",
       "  144: 42,\n",
       "  145: 43,\n",
       "  146: 44,\n",
       "  147: 45,\n",
       "  148: 46,\n",
       "  149: 47,\n",
       "  150: 48,\n",
       "  151: 49,\n",
       "  152: 50,\n",
       "  153: 51,\n",
       "  154: 52,\n",
       "  155: 53,\n",
       "  156: 54,\n",
       "  157: 55,\n",
       "  158: 56,\n",
       "  159: 57,\n",
       "  160: 58,\n",
       "  161: 59,\n",
       "  162: 60,\n",
       "  163: 61,\n",
       "  164: 62,\n",
       "  165: 63,\n",
       "  166: 64,\n",
       "  167: 65,\n",
       "  168: 66,\n",
       "  169: 67,\n",
       "  170: 68,\n",
       "  171: 69,\n",
       "  172: 70,\n",
       "  173: 71,\n",
       "  174: 72,\n",
       "  175: 73,\n",
       "  177: 74,\n",
       "  178: 75,\n",
       "  179: 76,\n",
       "  180: 77,\n",
       "  181: 78,\n",
       "  182: 79,\n",
       "  184: 80,\n",
       "  185: 81,\n",
       "  186: 82,\n",
       "  187: 83,\n",
       "  188: 84,\n",
       "  190: 85,\n",
       "  192: 86,\n",
       "  194: 87,\n",
       "  195: 88,\n",
       "  202: 89},\n",
       " {0: 0, 1: 1},\n",
       " {0.0: 0,\n",
       "  0.1: 1,\n",
       "  0.2: 2,\n",
       "  0.3: 3,\n",
       "  0.4: 4,\n",
       "  0.5: 5,\n",
       "  0.6: 6,\n",
       "  0.7: 7,\n",
       "  0.8: 8,\n",
       "  0.9: 9,\n",
       "  1.0: 10,\n",
       "  1.1: 11,\n",
       "  1.2: 12,\n",
       "  1.3: 13,\n",
       "  1.4: 14,\n",
       "  1.5: 15,\n",
       "  1.6: 16,\n",
       "  1.8: 17,\n",
       "  1.9: 18,\n",
       "  2.0: 19,\n",
       "  2.1: 20,\n",
       "  2.2: 21,\n",
       "  2.3: 22,\n",
       "  2.4: 23,\n",
       "  2.5: 24,\n",
       "  2.6: 25,\n",
       "  2.8: 26,\n",
       "  2.9: 27,\n",
       "  3.0: 28,\n",
       "  3.1: 29,\n",
       "  3.2: 30,\n",
       "  3.4: 31,\n",
       "  3.5: 32,\n",
       "  3.6: 33,\n",
       "  3.8: 34,\n",
       "  4.0: 35,\n",
       "  4.2: 36,\n",
       "  5.6: 37,\n",
       "  6.2: 38},\n",
       " {1: 0, 2: 1, 3: 2},\n",
       " {0: 0, 1: 1, 2: 2, 3: 3},\n",
       " {3: 0, 6: 1, 7: 2},\n",
       " {'absent': 0, 'present': 1}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-A 2)\n",
    "sym_dict =[]\n",
    "for i in range(len(a_list[0])):\n",
    "    temp=[]\n",
    "    for j in range(len(a_list)):\n",
    "        temp.append(a_list[j][i])\n",
    "    uniq_value = uniq_values(temp)\n",
    "    dic = {}\n",
    "    for k in range(len(uniq_value)):\n",
    "        dic[uniq_value[k]] =k\n",
    "    sym_dict.append(dic)\n",
    "    \n",
    "sym_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[36, 1, 3, 21, 128, 0, 2, 10, 0, 23, 1, 3, 0, 1],\n",
       " [33, 0, 2, 10, 143, 0, 2, 58, 0, 16, 1, 0, 2, 0],\n",
       " [23, 1, 1, 16, 84, 0, 0, 39, 0, 3, 0, 0, 2, 1],\n",
       " [30, 1, 3, 19, 86, 0, 0, 7, 1, 2, 1, 1, 2, 0],\n",
       " [38, 0, 1, 13, 92, 0, 2, 20, 1, 2, 0, 1, 0, 0],\n",
       " [31, 1, 3, 13, 11, 0, 0, 38, 0, 4, 0, 0, 2, 0],\n",
       " [22, 1, 2, 21, 79, 1, 2, 40, 1, 6, 1, 1, 1, 1],\n",
       " [25, 1, 3, 8, 64, 0, 2, 40, 1, 12, 1, 1, 2, 1],\n",
       " [26, 1, 3, 27, 108, 0, 2, 68, 0, 12, 1, 2, 2, 1],\n",
       " [29, 0, 3, 33, 140, 0, 2, 52, 0, 35, 1, 3, 2, 1],\n",
       " [25, 1, 3, 24, 60, 0, 0, 59, 0, 5, 1, 0, 2, 0],\n",
       " [19, 1, 3, 28, 52, 0, 2, 11, 1, 0, 0, 0, 2, 0],\n",
       " [10, 1, 2, 27, 61, 0, 2, 77, 0, 0, 0, 0, 0, 0],\n",
       " [27, 1, 0, 23, 60, 0, 0, 43, 0, 25, 1, 2, 0, 1],\n",
       " [23, 0, 3, 19, 115, 0, 2, 57, 0, 0, 0, 1, 0, 0],\n",
       " [37, 0, 3, 9, 2, 0, 0, 24, 0, 16, 1, 0, 0, 0],\n",
       " [12, 1, 3, 27, 122, 0, 0, 19, 1, 17, 1, 2, 2, 1],\n",
       " [19, 1, 3, 27, 29, 1, 2, 53, 1, 29, 2, 0, 2, 1],\n",
       " [30, 1, 0, 8, 37, 0, 2, 42, 1, 17, 1, 0, 0, 0],\n",
       " [6, 1, 0, 27, 26, 0, 0, 75, 1, 14, 0, 0, 2, 0],\n",
       " [33, 1, 3, 13, 55, 0, 2, 28, 1, 25, 1, 2, 2, 1],\n",
       " [14, 1, 1, 21, 69, 0, 2, 77, 0, 2, 1, 0, 0, 0],\n",
       " [9, 1, 3, 10, 115, 0, 0, 78, 0, 12, 1, 0, 0, 0],\n",
       " [13, 1, 3, 9, 30, 0, 0, 41, 0, 1, 0, 0, 0, 0],\n",
       " [20, 0, 1, 22, 105, 1, 2, 57, 1, 0, 0, 1, 0, 0],\n",
       " [14, 0, 2, 21, 97, 0, 0, 37, 0, 2, 0, 0, 0, 0],\n",
       " [12, 0, 3, 26, 67, 0, 2, 50, 1, 0, 1, 0, 0, 0],\n",
       " [17, 0, 2, 13, 110, 0, 2, 55, 0, 6, 0, 0, 0, 0],\n",
       " [24, 1, 2, 9, 56, 0, 2, 63, 0, 24, 1, 1, 2, 1],\n",
       " [37, 0, 2, 8, 88, 1, 2, 29, 0, 0, 0, 1, 0, 0],\n",
       " [23, 1, 2, 19, 55, 0, 2, 48, 0, 4, 1, 1, 2, 1],\n",
       " [32, 1, 3, 38, 54, 0, 2, 36, 0, 22, 0, 0, 1, 0],\n",
       " [3, 0, 2, 13, 41, 0, 0, 68, 0, 0, 0, 0, 0, 0],\n",
       " [25, 1, 3, 40, 130, 0, 2, 38, 1, 31, 2, 0, 2, 1],\n",
       " [16, 1, 3, 29, 27, 0, 2, 25, 1, 9, 1, 0, 2, 1],\n",
       " [14, 1, 3, 21, 79, 1, 2, 48, 1, 0, 0, 2, 2, 1],\n",
       " [27, 1, 3, 27, 33, 0, 2, 36, 1, 18, 0, 1, 2, 1],\n",
       " [25, 1, 0, 38, 95, 0, 2, 24, 0, 0, 0, 0, 0, 1],\n",
       " [8, 1, 2, 21, 13, 0, 0, 48, 0, 0, 0, 0, 0, 0],\n",
       " [14, 1, 3, 14, 48, 0, 2, 82, 0, 0, 0, 0, 0, 0],\n",
       " [6, 1, 3, 34, 49, 0, 0, 78, 0, 0, 0, 0, 2, 1],\n",
       " [28, 0, 3, 16, 35, 0, 0, 61, 0, 0, 0, 0, 0, 0],\n",
       " [10, 1, 2, 21, 59, 0, 0, 76, 1, 4, 0, 0, 0, 0],\n",
       " [12, 1, 1, 2, 24, 1, 0, 54, 0, 0, 0, 0, 2, 0],\n",
       " [25, 1, 2, 18, 44, 1, 0, 33, 0, 21, 1, 1, 1, 1],\n",
       " [24, 1, 2, 27, 37, 1, 2, 63, 0, 0, 0, 0, 0, 0],\n",
       " [15, 1, 2, 12, 2, 0, 2, 25, 0, 8, 0, 3, 0, 1],\n",
       " [10, 1, 3, 8, 24, 0, 2, 74, 0, 0, 0, 1, 0, 1],\n",
       " [32, 1, 1, 38, 70, 0, 0, 19, 1, 0, 1, 3, 1, 1],\n",
       " [31, 0, 3, 33, 51, 0, 2, 14, 0, 10, 1, 3, 2, 1],\n",
       " [8, 1, 3, 25, 124, 0, 0, 24, 1, 17, 1, 0, 1, 1],\n",
       " [18, 1, 1, 19, 31, 1, 0, 80, 0, 0, 0, 0, 0, 0],\n",
       " [31, 0, 2, 27, 142, 1, 2, 55, 0, 8, 0, 1, 0, 0],\n",
       " [29, 0, 1, 27, 22, 0, 0, 76, 0, 0, 0, 2, 0, 0],\n",
       " [11, 0, 1, 21, 60, 0, 2, 73, 0, 6, 1, 0, 0, 0],\n",
       " [7, 0, 1, 5, 25, 0, 0, 66, 0, 0, 0, 1, 0, 0],\n",
       " [27, 1, 3, 26, 5, 0, 2, 24, 1, 33, 1, 1, 0, 1],\n",
       " [26, 0, 2, 13, 12, 1, 0, 3, 0, 0, 0, 0, 0, 0],\n",
       " [25, 0, 3, 42, 73, 0, 0, 41, 1, 0, 1, 0, 0, 1],\n",
       " [28, 1, 1, 13, 100, 0, 2, 6, 0, 14, 1, 1, 2, 1],\n",
       " [23, 1, 2, 33, 0, 1, 0, 71, 0, 2, 0, 1, 2, 0],\n",
       " [17, 0, 3, 21, 117, 0, 0, 40, 1, 12, 1, 0, 2, 1],\n",
       " [10, 1, 2, 13, 52, 0, 0, 67, 0, 0, 0, 0, 0, 0],\n",
       " [26, 0, 0, 33, 65, 0, 0, 69, 0, 9, 0, 0, 0, 0],\n",
       " [29, 1, 0, 30, 59, 1, 2, 48, 0, 22, 2, 0, 1, 0],\n",
       " [23, 1, 3, 33, 98, 0, 2, 12, 1, 6, 1, 1, 1, 1],\n",
       " [17, 1, 3, 27, 84, 0, 2, 82, 1, 0, 0, 0, 0, 0],\n",
       " [24, 0, 1, 25, 126, 1, 2, 50, 0, 0, 0, 2, 0, 1],\n",
       " [10, 0, 2, 12, 66, 0, 0, 47, 0, 3, 1, 1, 0, 0],\n",
       " [13, 1, 2, 7, 67, 0, 0, 50, 0, 0, 0, 0, 0, 1],\n",
       " [27, 1, 3, 13, 83, 0, 0, 38, 1, 33, 1, 1, 2, 1],\n",
       " [23, 0, 3, 13, 137, 0, 0, 61, 1, 6, 0, 0, 0, 0],\n",
       " [36, 1, 1, 36, 69, 0, 2, 41, 0, 0, 0, 0, 0, 0],\n",
       " [39, 0, 2, 27, 24, 0, 1, 16, 0, 11, 1, 0, 0, 0],\n",
       " [33, 0, 3, 6, 49, 0, 0, 40, 0, 3, 0, 2, 0, 0],\n",
       " [11, 1, 3, 28, 121, 0, 2, 45, 1, 0, 1, 3, 2, 1],\n",
       " [11, 1, 3, 4, 34, 0, 2, 46, 1, 28, 1, 0, 0, 0],\n",
       " [5, 0, 2, 0, 26, 0, 0, 76, 0, 0, 0, 0, 0, 0],\n",
       " [8, 0, 2, 13, 35, 0, 0, 71, 0, 0, 1, 0, 0, 0],\n",
       " [22, 1, 1, 13, 62, 0, 0, 75, 0, 8, 0, 0, 0, 0],\n",
       " [24, 1, 3, 31, 44, 0, 0, 7, 0, 19, 1, 1, 2, 1],\n",
       " [2, 1, 3, 13, 25, 0, 0, 29, 1, 16, 1, 0, 2, 1],\n",
       " [24, 1, 3, 33, 93, 0, 2, 11, 1, 8, 0, 0, 2, 1],\n",
       " [7, 1, 2, 21, 40, 0, 2, 66, 0, 19, 1, 0, 0, 0],\n",
       " [23, 1, 3, 8, 28, 0, 0, 25, 1, 15, 1, 0, 1, 0],\n",
       " [8, 1, 0, 32, 68, 0, 2, 75, 0, 8, 0, 2, 0, 0],\n",
       " [28, 1, 1, 19, 34, 1, 2, 38, 0, 0, 0, 0, 0, 0],\n",
       " [25, 1, 0, 43, 93, 0, 2, 43, 0, 36, 2, 0, 2, 0],\n",
       " [7, 0, 1, 18, 118, 0, 0, 61, 0, 0, 0, 0, 0, 0],\n",
       " [16, 1, 3, 33, 67, 0, 2, 27, 0, 25, 1, 0, 2, 1],\n",
       " [25, 1, 1, 27, 47, 0, 0, 62, 1, 0, 0, 0, 0, 0],\n",
       " [27, 0, 3, 21, 132, 0, 2, 67, 0, 0, 0, 0, 0, 1],\n",
       " [20, 1, 3, 16, 89, 0, 2, 10, 1, 21, 1, 1, 2, 1],\n",
       " [20, 1, 3, 8, 32, 0, 2, 9, 1, 0, 1, 1, 0, 1],\n",
       " [18, 1, 3, 17, 38, 0, 0, 66, 0, 10, 0, 2, 2, 1],\n",
       " [13, 1, 3, 8, 97, 0, 2, 18, 1, 10, 1, 1, 0, 1],\n",
       " [32, 1, 3, 13, 114, 0, 2, 49, 0, 4, 1, 0, 0, 0],\n",
       " [24, 1, 3, 1, 60, 0, 0, 54, 0, 1, 0, 1, 2, 1],\n",
       " [30, 0, 2, 27, 123, 0, 0, 32, 0, 2, 0, 0, 2, 0],\n",
       " [16, 0, 1, 13, 68, 0, 0, 60, 0, 11, 0, 0, 0, 0],\n",
       " [10, 0, 2, 7, 1, 0, 0, 73, 0, 6, 1, 0, 0, 0],\n",
       " [33, 1, 3, 13, 63, 0, 0, 0, 0, 10, 1, 0, 0, 1],\n",
       " [15, 0, 3, 21, 92, 0, 0, 61, 0, 0, 0, 0, 0, 0],\n",
       " [23, 1, 3, 39, 106, 1, 2, 23, 0, 10, 1, 3, 2, 1],\n",
       " [29, 1, 3, 21, 77, 0, 2, 45, 0, 14, 1, 1, 2, 1],\n",
       " [14, 1, 3, 16, 96, 0, 2, 64, 0, 5, 1, 0, 2, 1],\n",
       " [17, 1, 2, 1, 48, 0, 0, 41, 1, 12, 1, 0, 0, 0],\n",
       " [26, 0, 3, 33, 81, 0, 2, 55, 0, 25, 1, 2, 2, 1],\n",
       " [25, 1, 3, 27, 11, 0, 0, 60, 1, 0, 0, 1, 2, 1],\n",
       " [11, 0, 1, 9, 3, 0, 0, 36, 0, 0, 1, 0, 0, 0],\n",
       " [21, 0, 3, 44, 131, 0, 1, 17, 1, 31, 1, 0, 0, 1],\n",
       " [7, 1, 1, 8, 61, 0, 0, 51, 0, 0, 0, 0, 0, 0],\n",
       " [26, 0, 3, 37, 117, 0, 2, 59, 0, 0, 0, 0, 0, 1],\n",
       " [20, 0, 2, 24, 116, 1, 0, 68, 0, 0, 0, 0, 0, 0],\n",
       " [8, 1, 1, 13, 110, 0, 0, 60, 0, 0, 0, 0, 0, 0],\n",
       " [15, 0, 1, 23, 94, 0, 0, 60, 0, 0, 1, 0, 0, 0],\n",
       " [12, 1, 3, 13, 73, 0, 2, 42, 0, 8, 0, 0, 2, 1],\n",
       " [22, 0, 3, 46, 105, 1, 2, 32, 1, 35, 2, 2, 2, 1],\n",
       " [32, 0, 0, 33, 52, 0, 0, 14, 0, 25, 2, 0, 0, 0],\n",
       " [22, 1, 3, 21, 102, 1, 2, 6, 1, 16, 2, 0, 2, 1],\n",
       " [15, 1, 2, 13, 19, 0, 0, 37, 0, 19, 1, 3, 2, 1],\n",
       " [20, 1, 3, 14, 104, 0, 2, 16, 1, 30, 1, 2, 0, 1],\n",
       " [23, 1, 3, 34, 96, 0, 0, 1, 1, 12, 1, 1, 2, 1],\n",
       " [31, 0, 2, 38, 138, 0, 2, 49, 0, 8, 0, 0, 0, 0],\n",
       " [20, 1, 2, 17, 95, 0, 2, 50, 0, 5, 2, 1, 0, 0],\n",
       " [20, 0, 2, 38, 28, 0, 0, 61, 0, 0, 0, 1, 0, 0],\n",
       " [28, 1, 3, 13, 90, 0, 0, 5, 1, 17, 1, 2, 2, 1],\n",
       " [18, 0, 2, 25, 23, 0, 2, 67, 0, 1, 1, 0, 0, 0],\n",
       " [18, 1, 1, 23, 28, 0, 0, 56, 0, 8, 0, 1, 0, 0],\n",
       " [26, 1, 3, 11, 56, 1, 0, 58, 1, 14, 0, 2, 2, 1],\n",
       " [29, 0, 3, 7, 92, 0, 0, 67, 1, 17, 1, 2, 0, 1],\n",
       " [32, 1, 3, 9, 38, 0, 2, 31, 1, 1, 0, 1, 0, 1],\n",
       " [8, 1, 3, 27, 52, 0, 0, 75, 0, 0, 0, 0, 0, 0],\n",
       " [30, 1, 3, 13, 70, 0, 2, 3, 1, 21, 2, 1, 0, 1],\n",
       " [20, 1, 2, 33, 58, 0, 2, 63, 0, 16, 0, 0, 2, 0],\n",
       " [12, 0, 2, 28, 11, 0, 2, 58, 1, 14, 2, 0, 0, 0],\n",
       " [33, 0, 2, 34, 99, 0, 0, 70, 0, 0, 0, 1, 0, 0],\n",
       " [22, 1, 3, 17, 73, 1, 2, 42, 1, 12, 1, 1, 0, 1],\n",
       " [1, 0, 1, 12, 36, 0, 0, 86, 0, 7, 0, 0, 0, 0],\n",
       " [23, 1, 3, 22, 33, 0, 0, 66, 1, 0, 0, 0, 2, 0],\n",
       " [30, 1, 3, 30, 38, 0, 2, 31, 0, 19, 1, 2, 1, 1],\n",
       " [25, 1, 3, 26, 94, 0, 2, 79, 0, 0, 0, 0, 0, 0],\n",
       " [16, 1, 2, 27, 59, 0, 0, 61, 0, 6, 1, 1, 2, 1],\n",
       " [17, 1, 0, 17, 39, 0, 2, 24, 1, 14, 0, 1, 0, 0],\n",
       " [20, 1, 1, 45, 102, 0, 2, 88, 0, 0, 0, 1, 2, 1],\n",
       " [19, 1, 3, 15, 101, 0, 0, 2, 1, 19, 1, 2, 2, 1],\n",
       " [18, 1, 3, 9, 56, 0, 0, 58, 0, 0, 0, 1, 0, 1],\n",
       " [6, 1, 3, 8, 6, 0, 2, 14, 1, 19, 1, 0, 2, 1],\n",
       " [24, 1, 2, 22, 50, 0, 2, 71, 0, 30, 0, 2, 2, 1],\n",
       " [7, 0, 2, 9, 91, 0, 2, 70, 1, 0, 0, 0, 0, 0],\n",
       " [7, 1, 2, 9, 74, 0, 0, 76, 0, 0, 0, 0, 0, 0],\n",
       " [16, 0, 2, 13, 45, 0, 0, 56, 0, 16, 1, 0, 0, 0],\n",
       " [20, 0, 2, 7, 90, 0, 2, 65, 0, 0, 0, 0, 0, 0],\n",
       " [30, 0, 3, 21, 115, 0, 0, 21, 0, 19, 1, 2, 0, 0],\n",
       " [17, 0, 2, 21, 79, 0, 2, 47, 0, 5, 0, 0, 0, 0],\n",
       " [12, 0, 1, 5, 30, 0, 0, 70, 0, 0, 0, 0, 0, 0],\n",
       " [21, 1, 3, 27, 43, 0, 0, 11, 1, 37, 2, 0, 2, 1],\n",
       " [11, 1, 1, 19, 120, 0, 2, 68, 0, 0, 0, 0, 0, 0],\n",
       " [22, 1, 0, 13, 21, 0, 2, 60, 0, 18, 1, 0, 2, 0],\n",
       " [32, 0, 3, 43, 54, 1, 0, 63, 1, 10, 1, 2, 2, 1],\n",
       " [4, 1, 0, 13, 57, 0, 0, 79, 1, 34, 1, 0, 2, 1],\n",
       " [28, 0, 3, 33, 68, 0, 0, 52, 1, 14, 1, 0, 0, 1],\n",
       " [21, 1, 1, 21, 85, 0, 0, 53, 0, 0, 0, 0, 0, 0],\n",
       " [24, 1, 3, 19, 82, 0, 2, 29, 1, 28, 1, 2, 2, 1],\n",
       " [9, 1, 3, 8, 37, 0, 0, 59, 0, 0, 0, 0, 2, 0],\n",
       " [30, 0, 3, 44, 129, 0, 0, 52, 1, 0, 0, 0, 0, 0],\n",
       " [16, 0, 3, 8, 77, 0, 2, 57, 0, 0, 0, 0, 0, 0],\n",
       " [19, 1, 2, 21, 24, 1, 2, 50, 0, 12, 2, 0, 0, 0],\n",
       " [11, 0, 3, 26, 62, 0, 2, 50, 1, 2, 1, 0, 0, 0],\n",
       " [31, 1, 0, 26, 101, 1, 2, 72, 0, 14, 1, 1, 0, 1],\n",
       " [35, 1, 0, 38, 60, 1, 2, 30, 0, 1, 1, 1, 0, 0],\n",
       " [35, 1, 2, 27, 77, 0, 2, 44, 0, 19, 1, 3, 2, 1],\n",
       " [33, 1, 3, 1, 112, 0, 2, 24, 1, 9, 1, 2, 0, 1],\n",
       " [34, 0, 2, 13, 37, 0, 2, 15, 0, 15, 1, 0, 0, 0],\n",
       " [1, 1, 0, 12, 14, 0, 2, 72, 0, 0, 0, 0, 0, 0],\n",
       " [28, 0, 3, 26, 109, 1, 0, 8, 0, 18, 1, 3, 0, 1],\n",
       " [17, 1, 3, 27, 111, 0, 0, 21, 1, 36, 1, 3, 2, 1],\n",
       " [12, 1, 2, 33, 57, 0, 0, 45, 0, 33, 1, 0, 0, 1],\n",
       " [33, 1, 3, 17, 77, 1, 0, 61, 0, 2, 1, 2, 2, 1],\n",
       " [16, 1, 2, 20, 23, 0, 0, 61, 0, 0, 0, 0, 0, 0],\n",
       " [8, 1, 2, 13, 65, 1, 0, 87, 0, 8, 2, 0, 2, 0],\n",
       " [22, 0, 3, 23, 141, 0, 2, 48, 1, 18, 1, 2, 2, 1],\n",
       " [7, 1, 3, 8, 8, 0, 2, 56, 0, 0, 0, 0, 2, 1],\n",
       " [8, 0, 3, 3, 88, 0, 2, 21, 0, 6, 1, 0, 0, 0],\n",
       " [19, 1, 2, 21, 70, 1, 2, 71, 0, 0, 0, 3, 0, 0],\n",
       " [9, 1, 2, 21, 124, 0, 0, 60, 0, 18, 0, 1, 0, 0],\n",
       " [22, 1, 3, 22, 16, 0, 2, 7, 1, 20, 1, 1, 1, 1],\n",
       " [18, 1, 3, 7, 59, 1, 0, 45, 0, 1, 0, 3, 2, 0],\n",
       " [28, 0, 3, 27, 139, 0, 2, 55, 0, 12, 1, 0, 0, 0],\n",
       " [36, 1, 2, 38, 92, 0, 0, 12, 1, 27, 1, 1, 2, 1],\n",
       " [20, 1, 3, 27, 64, 0, 0, 58, 0, 12, 0, 0, 0, 0],\n",
       " [36, 1, 3, 30, 9, 0, 0, 24, 1, 25, 2, 0, 2, 1],\n",
       " [20, 1, 1, 7, 121, 0, 0, 54, 0, 0, 0, 0, 2, 0],\n",
       " [2, 1, 3, 18, 101, 0, 2, 54, 1, 0, 0, 0, 2, 1],\n",
       " [14, 1, 2, 16, 78, 1, 0, 73, 0, 0, 0, 2, 0, 0],\n",
       " [21, 0, 1, 24, 74, 0, 2, 59, 0, 14, 1, 0, 0, 0],\n",
       " [24, 0, 3, 1, 72, 0, 2, 21, 0, 10, 1, 0, 0, 0],\n",
       " [20, 0, 2, 8, 40, 0, 0, 56, 0, 16, 1, 0, 0, 0],\n",
       " [35, 0, 0, 27, 64, 0, 0, 49, 0, 17, 0, 2, 0, 0],\n",
       " [40, 1, 3, 17, 116, 0, 2, 60, 1, 0, 0, 3, 0, 1],\n",
       " [34, 1, 2, 12, 99, 0, 0, 49, 0, 10, 0, 1, 2, 0],\n",
       " [24, 1, 3, 17, 113, 0, 2, 69, 0, 0, 0, 2, 2, 1],\n",
       " [26, 1, 3, 17, 81, 0, 2, 39, 1, 26, 1, 1, 2, 1],\n",
       " [17, 1, 3, 27, 112, 0, 0, 71, 1, 16, 0, 0, 2, 1],\n",
       " [21, 1, 3, 38, 106, 0, 2, 43, 1, 8, 1, 1, 2, 1],\n",
       " [18, 1, 0, 34, 111, 1, 0, 75, 0, 12, 1, 0, 2, 0],\n",
       " [26, 0, 2, 3, 125, 0, 0, 58, 0, 0, 0, 1, 0, 0],\n",
       " [24, 1, 2, 5, 65, 0, 2, 52, 1, 6, 1, 0, 2, 0],\n",
       " [30, 1, 2, 17, 121, 0, 0, 30, 1, 17, 1, 0, 2, 1],\n",
       " [3, 1, 2, 21, 74, 0, 0, 83, 0, 32, 2, 0, 0, 0],\n",
       " [25, 1, 0, 40, 105, 0, 2, 57, 0, 2, 1, 0, 2, 1],\n",
       " [17, 1, 2, 17, 69, 1, 2, 64, 0, 23, 1, 0, 0, 0],\n",
       " [9, 0, 2, 14, 39, 0, 0, 63, 0, 2, 1, 0, 0, 0],\n",
       " [24, 1, 3, 19, 42, 0, 2, 30, 1, 21, 1, 3, 2, 1],\n",
       " [0, 1, 1, 21, 30, 0, 2, 89, 0, 0, 0, 0, 0, 0],\n",
       " [7, 0, 1, 21, 30, 0, 2, 70, 0, 14, 0, 0, 0, 0],\n",
       " [29, 0, 2, 24, 75, 0, 2, 70, 0, 0, 0, 0, 0, 0],\n",
       " [17, 1, 2, 0, 53, 0, 0, 52, 1, 0, 0, 1, 2, 0],\n",
       " [20, 1, 2, 13, 81, 0, 2, 45, 0, 4, 1, 0, 2, 0],\n",
       " [10, 1, 1, 13, 46, 0, 0, 68, 0, 0, 0, 0, 0, 0],\n",
       " [20, 1, 3, 8, 64, 0, 0, 25, 1, 26, 1, 1, 2, 1],\n",
       " [31, 1, 3, 24, 77, 0, 2, 26, 0, 26, 1, 1, 2, 1],\n",
       " [23, 1, 2, 33, 7, 0, 0, 72, 0, 16, 0, 0, 0, 0],\n",
       " [29, 1, 3, 21, 132, 1, 2, 31, 1, 17, 0, 3, 2, 1],\n",
       " [2, 0, 3, 26, 15, 0, 0, 79, 0, 14, 0, 0, 0, 0],\n",
       " [7, 1, 1, 24, 29, 0, 0, 31, 0, 0, 1, 0, 1, 0],\n",
       " [28, 0, 2, 21, 86, 0, 0, 4, 0, 12, 1, 1, 2, 1],\n",
       " [9, 0, 3, 22, 135, 1, 2, 34, 1, 28, 1, 0, 2, 1],\n",
       " [24, 0, 0, 33, 102, 1, 2, 60, 0, 10, 0, 0, 0, 0],\n",
       " [18, 1, 0, 12, 18, 0, 2, 85, 0, 0, 1, 0, 1, 0],\n",
       " [27, 0, 3, 30, 119, 0, 2, 44, 1, 10, 1, 0, 2, 1],\n",
       " [5, 1, 3, 12, 45, 0, 0, 38, 0, 12, 1, 0, 2, 1],\n",
       " [11, 1, 3, 10, 83, 0, 2, 81, 0, 0, 0, 0, 0, 0],\n",
       " [18, 1, 3, 19, 78, 0, 0, 59, 1, 0, 0, 1, 2, 1],\n",
       " [28, 1, 2, 21, 57, 0, 0, 44, 0, 17, 1, 3, 2, 0],\n",
       " [28, 0, 3, 38, 4, 0, 2, 43, 0, 38, 2, 3, 2, 1],\n",
       " [19, 0, 3, 26, 60, 0, 2, 58, 0, 0, 0, 0, 0, 0],\n",
       " [9, 1, 3, 13, 11, 0, 2, 19, 1, 24, 1, 0, 2, 1],\n",
       " [13, 1, 2, 26, 80, 0, 2, 54, 0, 0, 0, 0, 0, 0],\n",
       " [18, 1, 1, 13, 129, 0, 0, 70, 0, 2, 0, 0, 0, 0],\n",
       " [34, 1, 2, 44, 96, 1, 2, 48, 1, 16, 1, 0, 2, 1],\n",
       " [5, 1, 2, 27, 127, 0, 2, 79, 0, 0, 0, 0, 0, 0],\n",
       " [19, 0, 3, 21, 87, 0, 2, 41, 0, 4, 1, 0, 0, 0],\n",
       " [28, 0, 3, 27, 91, 0, 2, 58, 0, 33, 2, 2, 0, 1],\n",
       " [17, 0, 2, 27, 120, 0, 2, 40, 0, 15, 0, 1, 0, 0],\n",
       " [26, 1, 3, 21, 76, 0, 0, 42, 1, 14, 0, 1, 2, 1],\n",
       " [31, 1, 3, 8, 72, 0, 2, 56, 0, 6, 0, 2, 1, 1],\n",
       " [31, 0, 2, 35, 92, 0, 0, 46, 0, 8, 0, 0, 0, 0],\n",
       " [26, 1, 2, 27, 17, 0, 2, 53, 0, 28, 1, 0, 0, 1],\n",
       " [26, 1, 3, 30, 101, 0, 2, 40, 1, 26, 1, 2, 2, 1],\n",
       " [20, 1, 3, 13, 19, 0, 0, 13, 0, 14, 1, 1, 2, 1],\n",
       " [10, 1, 1, 21, 45, 0, 2, 84, 0, 0, 0, 0, 0, 0],\n",
       " [10, 1, 3, 9, 107, 0, 2, 51, 0, 0, 0, 1, 0, 1],\n",
       " [17, 1, 2, 8, 10, 0, 0, 22, 0, 6, 0, 0, 0, 0],\n",
       " [25, 1, 2, 33, 38, 1, 0, 55, 0, 16, 0, 0, 0, 0],\n",
       " [37, 0, 1, 38, 114, 0, 0, 60, 0, 4, 0, 2, 0, 0],\n",
       " [27, 1, 2, 33, 67, 1, 0, 35, 1, 10, 1, 0, 0, 0],\n",
       " [21, 1, 3, 22, 136, 0, 0, 31, 1, 12, 1, 1, 2, 1],\n",
       " [30, 1, 2, 27, 133, 0, 0, 56, 0, 0, 0, 0, 0, 1],\n",
       " [9, 1, 3, 33, 71, 0, 0, 69, 0, 15, 0, 0, 0, 0],\n",
       " [24, 0, 2, 13, 134, 0, 0, 70, 0, 0, 0, 0, 0, 0],\n",
       " [26, 1, 3, 21, 32, 0, 2, 31, 1, 23, 1, 2, 2, 1],\n",
       " [24, 1, 1, 13, 103, 0, 2, 58, 0, 17, 1, 0, 0, 1],\n",
       " [15, 1, 1, 21, 89, 0, 0, 69, 0, 6, 0, 0, 0, 0],\n",
       " [14, 1, 1, 8, 55, 0, 0, 66, 0, 10, 2, 0, 2, 1],\n",
       " [18, 1, 2, 41, 26, 1, 0, 60, 0, 5, 0, 0, 2, 0],\n",
       " [10, 1, 1, 13, 86, 0, 0, 71, 0, 0, 0, 0, 2, 0],\n",
       " [22, 0, 1, 27, 109, 0, 2, 51, 0, 13, 1, 0, 0, 0],\n",
       " [23, 1, 3, 27, 20, 0, 0, 46, 0, 4, 1, 0, 1, 0],\n",
       " [33, 1, 3, 38, 104, 0, 2, 9, 1, 15, 1, 3, 0, 1]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-A 3)\n",
    "for i in range(len(a_list[0])):\n",
    "    integer = sym_dict[i]\n",
    "    for j in range(len(a_list)):\n",
    "        s=a_list[j][i]\n",
    "        a_list[j][i]= integer[s]\n",
    "        \n",
    "a_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36, 2, 4, 30, 38, 2, 3, 25, 2, 29, 3, 4, 3, 2], [33, 0, 2, 10, 142, 0, 2, 58, 0, 16, 1, 0, 2, 0], [23, 1, 1, 16, 84, 0, 0, 39, 0, 3, 0, 0, 2, 1], [30, 1, 3, 19, 86, 0, 0, 7, 1, 2, 1, 1, 2, 0], [38, 0, 1, 13, 92, 0, 2, 20, 1, 2, 0, 1, 0, 0], [31, 1, 3, 13, 11, 0, 0, 38, 0, 4, 0, 0, 2, 0], [22, 1, 2, 21, 79, 1, 2, 40, 1, 6, 1, 1, 1, 1], [25, 1, 3, 8, 64, 0, 2, 40, 1, 12, 1, 1, 2, 1], [26, 1, 3, 27, 108, 0, 2, 68, 0, 12, 1, 2, 2, 1], [29, 0, 3, 33, 139, 0, 2, 52, 0, 35, 1, 3, 2, 1], [25, 1, 3, 24, 60, 0, 0, 59, 0, 5, 1, 0, 2, 0], [19, 1, 3, 28, 52, 0, 2, 11, 1, 0, 0, 0, 2, 0], [10, 1, 2, 27, 61, 0, 2, 77, 0, 0, 0, 0, 0, 0], [27, 1, 0, 23, 60, 0, 0, 43, 0, 25, 1, 2, 0, 1], [23, 0, 3, 19, 115, 0, 2, 57, 0, 0, 0, 1, 0, 0], [37, 0, 3, 9, 2, 0, 0, 24, 0, 16, 1, 0, 0, 0], [12, 1, 3, 27, 122, 0, 0, 19, 1, 17, 1, 2, 2, 1], [19, 1, 3, 27, 29, 1, 2, 53, 1, 29, 2, 0, 2, 1], [30, 1, 0, 8, 37, 0, 2, 42, 1, 17, 1, 0, 0, 0], [6, 1, 0, 27, 26, 0, 0, 75, 1, 14, 0, 0, 2, 0], [33, 1, 3, 13, 55, 0, 2, 28, 1, 25, 1, 2, 2, 1], [14, 1, 1, 21, 69, 0, 2, 77, 0, 2, 1, 0, 0, 0], [9, 1, 3, 10, 115, 0, 0, 78, 0, 12, 1, 0, 0, 0], [13, 1, 3, 9, 30, 0, 0, 41, 0, 1, 0, 0, 0, 0], [20, 0, 1, 22, 105, 1, 2, 57, 1, 0, 0, 1, 0, 0], [14, 0, 2, 21, 97, 0, 0, 37, 0, 2, 0, 0, 0, 0], [12, 0, 3, 26, 67, 0, 2, 50, 1, 0, 1, 0, 0, 0], [17, 0, 2, 13, 110, 0, 2, 55, 0, 6, 0, 0, 0, 0], [24, 1, 2, 9, 56, 0, 2, 63, 0, 24, 1, 1, 2, 1], [37, 0, 2, 8, 88, 1, 2, 29, 0, 0, 0, 1, 0, 0], [23, 1, 2, 19, 55, 0, 2, 48, 0, 4, 1, 1, 2, 1], [32, 1, 3, 38, 54, 0, 2, 36, 0, 22, 0, 0, 1, 0], [3, 0, 2, 13, 41, 0, 0, 68, 0, 0, 0, 0, 0, 0], [25, 1, 3, 40, 129, 0, 2, 38, 1, 31, 2, 0, 2, 1], [16, 1, 3, 29, 27, 0, 2, 25, 1, 9, 1, 0, 2, 1], [14, 1, 3, 21, 79, 1, 2, 48, 1, 0, 0, 2, 2, 1], [27, 1, 3, 27, 33, 0, 2, 36, 1, 18, 0, 1, 2, 1], [25, 1, 0, 38, 95, 0, 2, 24, 0, 0, 0, 0, 0, 1], [8, 1, 2, 21, 13, 0, 0, 48, 0, 0, 0, 0, 0, 0], [14, 1, 3, 14, 48, 0, 2, 82, 0, 0, 0, 0, 0, 0], [6, 1, 3, 34, 49, 0, 0, 78, 0, 0, 0, 0, 2, 1], [28, 0, 3, 16, 35, 0, 0, 61, 0, 0, 0, 0, 0, 0], [10, 1, 2, 21, 59, 0, 0, 76, 1, 4, 0, 0, 0, 0], [12, 1, 1, 2, 24, 1, 0, 54, 0, 0, 0, 0, 2, 0], [25, 1, 2, 18, 44, 1, 0, 33, 0, 21, 1, 1, 1, 1], [24, 1, 2, 27, 37, 1, 2, 63, 0, 0, 0, 0, 0, 0], [15, 1, 2, 12, 2, 0, 2, 25, 0, 8, 0, 3, 0, 1], [10, 1, 3, 8, 24, 0, 2, 74, 0, 0, 0, 1, 0, 1], [32, 1, 1, 38, 70, 0, 0, 19, 1, 0, 1, 3, 1, 1], [31, 0, 3, 33, 51, 0, 2, 14, 0, 10, 1, 3, 2, 1], [8, 1, 3, 25, 124, 0, 0, 24, 1, 17, 1, 0, 1, 1], [18, 1, 1, 19, 31, 1, 0, 80, 0, 0, 0, 0, 0, 0], [31, 0, 2, 27, 141, 1, 2, 55, 0, 8, 0, 1, 0, 0], [29, 0, 1, 27, 22, 0, 0, 76, 0, 0, 0, 2, 0, 0], [11, 0, 1, 21, 60, 0, 2, 73, 0, 6, 1, 0, 0, 0], [7, 0, 1, 5, 25, 0, 0, 66, 0, 0, 0, 1, 0, 0], [27, 1, 3, 26, 5, 0, 2, 24, 1, 33, 1, 1, 0, 1], [26, 0, 2, 13, 12, 1, 0, 3, 0, 0, 0, 0, 0, 0], [25, 0, 3, 42, 73, 0, 0, 41, 1, 0, 1, 0, 0, 1], [28, 1, 1, 13, 100, 0, 2, 6, 0, 14, 1, 1, 2, 1], [23, 1, 2, 33, 0, 1, 0, 71, 0, 2, 0, 1, 2, 0], [17, 0, 3, 21, 117, 0, 0, 40, 1, 12, 1, 0, 2, 1], [10, 1, 2, 13, 52, 0, 0, 67, 0, 0, 0, 0, 0, 0], [26, 0, 0, 33, 65, 0, 0, 69, 0, 9, 0, 0, 0, 0], [29, 1, 0, 30, 59, 1, 2, 48, 0, 22, 2, 0, 1, 0], [23, 1, 3, 33, 98, 0, 2, 12, 1, 6, 1, 1, 1, 1], [17, 1, 3, 27, 84, 0, 2, 82, 1, 0, 0, 0, 0, 0], [24, 0, 1, 25, 126, 1, 2, 50, 0, 0, 0, 2, 0, 1], [10, 0, 2, 12, 66, 0, 0, 47, 0, 3, 1, 1, 0, 0], [13, 1, 2, 7, 67, 0, 0, 50, 0, 0, 0, 0, 0, 1], [27, 1, 3, 13, 83, 0, 0, 38, 1, 33, 1, 1, 2, 1], [23, 0, 3, 13, 136, 0, 0, 61, 1, 6, 0, 0, 0, 0], [36, 1, 1, 36, 69, 0, 2, 41, 0, 0, 0, 0, 0, 0], [39, 0, 2, 27, 24, 0, 1, 16, 0, 11, 1, 0, 0, 0], [33, 0, 3, 6, 49, 0, 0, 40, 0, 3, 0, 2, 0, 0], [11, 1, 3, 28, 121, 0, 2, 45, 1, 0, 1, 3, 2, 1], [11, 1, 3, 4, 34, 0, 2, 46, 1, 28, 1, 0, 0, 0], [5, 0, 2, 0, 26, 0, 0, 76, 0, 0, 0, 0, 0, 0], [8, 0, 2, 13, 35, 0, 0, 71, 0, 0, 1, 0, 0, 0], [22, 1, 1, 13, 62, 0, 0, 75, 0, 8, 0, 0, 0, 0], [24, 1, 3, 31, 44, 0, 0, 7, 0, 19, 1, 1, 2, 1], [2, 1, 3, 13, 25, 0, 0, 29, 1, 16, 1, 0, 2, 1], [24, 1, 3, 33, 93, 0, 2, 11, 1, 8, 0, 0, 2, 1], [7, 1, 2, 21, 40, 0, 2, 66, 0, 19, 1, 0, 0, 0], [23, 1, 3, 8, 28, 0, 0, 25, 1, 15, 1, 0, 1, 0], [8, 1, 0, 32, 68, 0, 2, 75, 0, 8, 0, 2, 0, 0], [28, 1, 1, 19, 34, 1, 2, 38, 0, 0, 0, 0, 0, 0], [25, 1, 0, 43, 93, 0, 2, 43, 0, 36, 2, 0, 2, 0], [7, 0, 1, 18, 118, 0, 0, 61, 0, 0, 0, 0, 0, 0], [16, 1, 3, 33, 67, 0, 2, 27, 0, 25, 1, 0, 2, 1], [25, 1, 1, 27, 47, 0, 0, 62, 1, 0, 0, 0, 0, 0], [27, 0, 3, 21, 131, 0, 2, 67, 0, 0, 0, 0, 0, 1], [20, 1, 3, 16, 89, 0, 2, 10, 1, 21, 1, 1, 2, 1], [20, 1, 3, 8, 32, 0, 2, 9, 1, 0, 1, 1, 0, 1], [18, 1, 3, 17, 38, 0, 0, 66, 0, 10, 0, 2, 2, 1], [13, 1, 3, 8, 97, 0, 2, 18, 1, 10, 1, 1, 0, 1], [32, 1, 3, 13, 114, 0, 2, 49, 0, 4, 1, 0, 0, 0], [24, 1, 3, 1, 60, 0, 0, 54, 0, 1, 0, 1, 2, 1], [30, 0, 2, 27, 123, 0, 0, 32, 0, 2, 0, 0, 2, 0], [16, 0, 1, 13, 68, 0, 0, 60, 0, 11, 0, 0, 0, 0], [10, 0, 2, 7, 1, 0, 0, 73, 0, 6, 1, 0, 0, 0], [33, 1, 3, 13, 63, 0, 0, 0, 0, 10, 1, 0, 0, 1], [15, 0, 3, 21, 92, 0, 0, 61, 0, 0, 0, 0, 0, 0], [23, 1, 3, 39, 106, 1, 2, 23, 0, 10, 1, 3, 2, 1], [29, 1, 3, 21, 77, 0, 2, 45, 0, 14, 1, 1, 2, 1], [14, 1, 3, 16, 96, 0, 2, 64, 0, 5, 1, 0, 2, 1], [17, 1, 2, 1, 48, 0, 0, 41, 1, 12, 1, 0, 0, 0], [26, 0, 3, 33, 81, 0, 2, 55, 0, 25, 1, 2, 2, 1], [25, 1, 3, 27, 11, 0, 0, 60, 1, 0, 0, 1, 2, 1], [11, 0, 1, 9, 3, 0, 0, 36, 0, 0, 1, 0, 0, 0], [21, 0, 3, 44, 130, 0, 1, 17, 1, 31, 1, 0, 0, 1], [7, 1, 1, 8, 61, 0, 0, 51, 0, 0, 0, 0, 0, 0], [26, 0, 3, 37, 117, 0, 2, 59, 0, 0, 0, 0, 0, 1], [20, 0, 2, 24, 116, 1, 0, 68, 0, 0, 0, 0, 0, 0], [8, 1, 1, 13, 110, 0, 0, 60, 0, 0, 0, 0, 0, 0], [15, 0, 1, 23, 94, 0, 0, 60, 0, 0, 1, 0, 0, 0], [12, 1, 3, 13, 73, 0, 2, 42, 0, 8, 0, 0, 2, 1], [22, 0, 3, 46, 105, 1, 2, 32, 1, 35, 2, 2, 2, 1], [32, 0, 0, 33, 52, 0, 0, 14, 0, 25, 2, 0, 0, 0], [22, 1, 3, 21, 102, 1, 2, 6, 1, 16, 2, 0, 2, 1], [15, 1, 2, 13, 19, 0, 0, 37, 0, 19, 1, 3, 2, 1], [20, 1, 3, 14, 104, 0, 2, 16, 1, 30, 1, 2, 0, 1], [23, 1, 3, 34, 96, 0, 0, 1, 1, 12, 1, 1, 2, 1], [31, 0, 2, 38, 137, 0, 2, 49, 0, 8, 0, 0, 0, 0], [20, 1, 2, 17, 95, 0, 2, 50, 0, 5, 2, 1, 0, 0], [20, 0, 2, 38, 28, 0, 0, 61, 0, 0, 0, 1, 0, 0], [28, 1, 3, 13, 90, 0, 0, 5, 1, 17, 1, 2, 2, 1], [18, 0, 2, 25, 23, 0, 2, 67, 0, 1, 1, 0, 0, 0], [18, 1, 1, 23, 28, 0, 0, 56, 0, 8, 0, 1, 0, 0], [26, 1, 3, 11, 56, 1, 0, 58, 1, 14, 0, 2, 2, 1], [29, 0, 3, 7, 92, 0, 0, 67, 1, 17, 1, 2, 0, 1], [32, 1, 3, 9, 38, 0, 2, 31, 1, 1, 0, 1, 0, 1], [8, 1, 3, 27, 52, 0, 0, 75, 0, 0, 0, 0, 0, 0], [30, 1, 3, 13, 70, 0, 2, 3, 1, 21, 2, 1, 0, 1], [20, 1, 2, 33, 58, 0, 2, 63, 0, 16, 0, 0, 2, 0], [12, 0, 2, 28, 11, 0, 2, 58, 1, 14, 2, 0, 0, 0], [33, 0, 2, 34, 99, 0, 0, 70, 0, 0, 0, 1, 0, 0], [22, 1, 3, 17, 73, 1, 2, 42, 1, 12, 1, 1, 0, 1], [1, 0, 1, 12, 36, 0, 0, 86, 0, 7, 0, 0, 0, 0], [23, 1, 3, 22, 33, 0, 0, 66, 1, 0, 0, 0, 2, 0], [30, 1, 3, 30, 38, 0, 2, 31, 0, 19, 1, 2, 1, 1], [25, 1, 3, 26, 94, 0, 2, 79, 0, 0, 0, 0, 0, 0], [16, 1, 2, 27, 59, 0, 0, 61, 0, 6, 1, 1, 2, 1], [17, 1, 0, 17, 39, 0, 2, 24, 1, 14, 0, 1, 0, 0], [20, 1, 1, 45, 102, 0, 2, 88, 0, 0, 0, 1, 2, 1], [19, 1, 3, 15, 101, 0, 0, 2, 1, 19, 1, 2, 2, 1], [18, 1, 3, 9, 56, 0, 0, 58, 0, 0, 0, 1, 0, 1], [6, 1, 3, 8, 6, 0, 2, 14, 1, 19, 1, 0, 2, 1], [24, 1, 2, 22, 50, 0, 2, 71, 0, 30, 0, 2, 2, 1], [7, 0, 2, 9, 91, 0, 2, 70, 1, 0, 0, 0, 0, 0], [7, 1, 2, 9, 74, 0, 0, 76, 0, 0, 0, 0, 0, 0], [16, 0, 2, 13, 45, 0, 0, 56, 0, 16, 1, 0, 0, 0], [20, 0, 2, 7, 90, 0, 2, 65, 0, 0, 0, 0, 0, 0], [30, 0, 3, 21, 115, 0, 0, 21, 0, 19, 1, 2, 0, 0], [17, 0, 2, 21, 79, 0, 2, 47, 0, 5, 0, 0, 0, 0], [12, 0, 1, 5, 30, 0, 0, 70, 0, 0, 0, 0, 0, 0], [21, 1, 3, 27, 43, 0, 0, 11, 1, 37, 2, 0, 2, 1], [11, 1, 1, 19, 120, 0, 2, 68, 0, 0, 0, 0, 0, 0], [22, 1, 0, 13, 21, 0, 2, 60, 0, 18, 1, 0, 2, 0], [32, 0, 3, 43, 54, 1, 0, 63, 1, 10, 1, 2, 2, 1], [4, 1, 0, 13, 57, 0, 0, 79, 1, 34, 1, 0, 2, 1], [28, 0, 3, 33, 68, 0, 0, 52, 1, 14, 1, 0, 0, 1], [21, 1, 1, 21, 85, 0, 0, 53, 0, 0, 0, 0, 0, 0], [24, 1, 3, 19, 82, 0, 2, 29, 1, 28, 1, 2, 2, 1], [9, 1, 3, 8, 37, 0, 0, 59, 0, 0, 0, 0, 2, 0], [30, 0, 3, 44, 128, 0, 0, 52, 1, 0, 0, 0, 0, 0], [16, 0, 3, 8, 77, 0, 2, 57, 0, 0, 0, 0, 0, 0], [19, 1, 2, 21, 24, 1, 2, 50, 0, 12, 2, 0, 0, 0], [11, 0, 3, 26, 62, 0, 2, 50, 1, 2, 1, 0, 0, 0], [31, 1, 0, 26, 101, 1, 2, 72, 0, 14, 1, 1, 0, 1], [35, 1, 0, 38, 60, 1, 2, 30, 0, 1, 1, 1, 0, 0], [35, 1, 2, 27, 77, 0, 2, 44, 0, 19, 1, 3, 2, 1], [33, 1, 3, 1, 112, 0, 2, 24, 1, 9, 1, 2, 0, 1], [34, 0, 2, 13, 37, 0, 2, 15, 0, 15, 1, 0, 0, 0], [1, 1, 0, 12, 14, 0, 2, 72, 0, 0, 0, 0, 0, 0], [28, 0, 3, 26, 109, 1, 0, 8, 0, 18, 1, 3, 0, 1], [17, 1, 3, 27, 111, 0, 0, 21, 1, 36, 1, 3, 2, 1], [12, 1, 2, 33, 57, 0, 0, 45, 0, 33, 1, 0, 0, 1], [33, 1, 3, 17, 77, 1, 0, 61, 0, 2, 1, 2, 2, 1], [16, 1, 2, 20, 23, 0, 0, 61, 0, 0, 0, 0, 0, 0], [8, 1, 2, 13, 65, 1, 0, 87, 0, 8, 2, 0, 2, 0], [22, 0, 3, 23, 140, 0, 2, 48, 1, 18, 1, 2, 2, 1], [7, 1, 3, 8, 8, 0, 2, 56, 0, 0, 0, 0, 2, 1], [8, 0, 3, 3, 88, 0, 2, 21, 0, 6, 1, 0, 0, 0], [19, 1, 2, 21, 70, 1, 2, 71, 0, 0, 0, 3, 0, 0], [9, 1, 2, 21, 124, 0, 0, 60, 0, 18, 0, 1, 0, 0], [22, 1, 3, 22, 16, 0, 2, 7, 1, 20, 1, 1, 1, 1], [18, 1, 3, 7, 59, 1, 0, 45, 0, 1, 0, 3, 2, 0], [28, 0, 3, 27, 138, 0, 2, 55, 0, 12, 1, 0, 0, 0], [36, 1, 2, 38, 92, 0, 0, 12, 1, 27, 1, 1, 2, 1], [20, 1, 3, 27, 64, 0, 0, 58, 0, 12, 0, 0, 0, 0], [36, 1, 3, 30, 9, 0, 0, 24, 1, 25, 2, 0, 2, 1], [20, 1, 1, 7, 121, 0, 0, 54, 0, 0, 0, 0, 2, 0], [2, 1, 3, 18, 101, 0, 2, 54, 1, 0, 0, 0, 2, 1], [14, 1, 2, 16, 78, 1, 0, 73, 0, 0, 0, 2, 0, 0], [21, 0, 1, 24, 74, 0, 2, 59, 0, 14, 1, 0, 0, 0], [24, 0, 3, 1, 72, 0, 2, 21, 0, 10, 1, 0, 0, 0], [20, 0, 2, 8, 40, 0, 0, 56, 0, 16, 1, 0, 0, 0], [35, 0, 0, 27, 64, 0, 0, 49, 0, 17, 0, 2, 0, 0], [40, 1, 3, 17, 116, 0, 2, 60, 1, 0, 0, 3, 0, 1], [34, 1, 2, 12, 99, 0, 0, 49, 0, 10, 0, 1, 2, 0], [24, 1, 3, 17, 113, 0, 2, 69, 0, 0, 0, 2, 2, 1], [26, 1, 3, 17, 81, 0, 2, 39, 1, 26, 1, 1, 2, 1], [17, 1, 3, 27, 112, 0, 0, 71, 1, 16, 0, 0, 2, 1], [21, 1, 3, 38, 106, 0, 2, 43, 1, 8, 1, 1, 2, 1], [18, 1, 0, 34, 111, 1, 0, 75, 0, 12, 1, 0, 2, 0], [26, 0, 2, 3, 125, 0, 0, 58, 0, 0, 0, 1, 0, 0], [24, 1, 2, 5, 65, 0, 2, 52, 1, 6, 1, 0, 2, 0], [30, 1, 2, 17, 121, 0, 0, 30, 1, 17, 1, 0, 2, 1], [3, 1, 2, 21, 74, 0, 0, 83, 0, 32, 2, 0, 0, 0], [25, 1, 0, 40, 105, 0, 2, 57, 0, 2, 1, 0, 2, 1], [17, 1, 2, 17, 69, 1, 2, 64, 0, 23, 1, 0, 0, 0], [9, 0, 2, 14, 39, 0, 0, 63, 0, 2, 1, 0, 0, 0], [24, 1, 3, 19, 42, 0, 2, 30, 1, 21, 1, 3, 2, 1], [0, 1, 1, 21, 30, 0, 2, 89, 0, 0, 0, 0, 0, 0], [7, 0, 1, 21, 30, 0, 2, 70, 0, 14, 0, 0, 0, 0], [29, 0, 2, 24, 75, 0, 2, 70, 0, 0, 0, 0, 0, 0], [17, 1, 2, 0, 53, 0, 0, 52, 1, 0, 0, 1, 2, 0], [20, 1, 2, 13, 81, 0, 2, 45, 0, 4, 1, 0, 2, 0], [10, 1, 1, 13, 46, 0, 0, 68, 0, 0, 0, 0, 0, 0], [20, 1, 3, 8, 64, 0, 0, 25, 1, 26, 1, 1, 2, 1], [31, 1, 3, 24, 77, 0, 2, 26, 0, 26, 1, 1, 2, 1], [23, 1, 2, 33, 7, 0, 0, 72, 0, 16, 0, 0, 0, 0], [29, 1, 3, 21, 131, 1, 2, 31, 1, 17, 0, 3, 2, 1], [2, 0, 3, 26, 15, 0, 0, 79, 0, 14, 0, 0, 0, 0], [7, 1, 1, 24, 29, 0, 0, 31, 0, 0, 1, 0, 1, 0], [28, 0, 2, 21, 86, 0, 0, 4, 0, 12, 1, 1, 2, 1], [9, 0, 3, 22, 134, 1, 2, 34, 1, 28, 1, 0, 2, 1], [24, 0, 0, 33, 102, 1, 2, 60, 0, 10, 0, 0, 0, 0], [18, 1, 0, 12, 18, 0, 2, 85, 0, 0, 1, 0, 1, 0], [27, 0, 3, 30, 119, 0, 2, 44, 1, 10, 1, 0, 2, 1], [5, 1, 3, 12, 45, 0, 0, 38, 0, 12, 1, 0, 2, 1], [11, 1, 3, 10, 83, 0, 2, 81, 0, 0, 0, 0, 0, 0], [18, 1, 3, 19, 78, 0, 0, 59, 1, 0, 0, 1, 2, 1], [28, 1, 2, 21, 57, 0, 0, 44, 0, 17, 1, 3, 2, 0], [28, 0, 3, 38, 4, 0, 2, 43, 0, 38, 2, 3, 2, 1], [19, 0, 3, 26, 60, 0, 2, 58, 0, 0, 0, 0, 0, 0], [9, 1, 3, 13, 11, 0, 2, 19, 1, 24, 1, 0, 2, 1], [13, 1, 2, 26, 80, 0, 2, 54, 0, 0, 0, 0, 0, 0], [18, 1, 1, 13, 128, 0, 0, 70, 0, 2, 0, 0, 0, 0], [34, 1, 2, 44, 96, 1, 2, 48, 1, 16, 1, 0, 2, 1], [5, 1, 2, 27, 127, 0, 2, 79, 0, 0, 0, 0, 0, 0], [19, 0, 3, 21, 87, 0, 2, 41, 0, 4, 1, 0, 0, 0], [28, 0, 3, 27, 91, 0, 2, 58, 0, 33, 2, 2, 0, 1], [17, 0, 2, 27, 120, 0, 2, 40, 0, 15, 0, 1, 0, 0], [26, 1, 3, 21, 76, 0, 0, 42, 1, 14, 0, 1, 2, 1], [31, 1, 3, 8, 72, 0, 2, 56, 0, 6, 0, 2, 1, 1], [31, 0, 2, 35, 92, 0, 0, 46, 0, 8, 0, 0, 0, 0], [26, 1, 2, 27, 17, 0, 2, 53, 0, 28, 1, 0, 0, 1], [26, 1, 3, 30, 101, 0, 2, 40, 1, 26, 1, 2, 2, 1], [20, 1, 3, 13, 19, 0, 0, 13, 0, 14, 1, 1, 2, 1], [10, 1, 1, 21, 45, 0, 2, 84, 0, 0, 0, 0, 0, 0], [10, 1, 3, 9, 107, 0, 2, 51, 0, 0, 0, 1, 0, 1], [17, 1, 2, 8, 10, 0, 0, 22, 0, 6, 0, 0, 0, 0], [25, 1, 2, 33, 38, 1, 0, 55, 0, 16, 0, 0, 0, 0], [37, 0, 1, 38, 114, 0, 0, 60, 0, 4, 0, 2, 0, 0], [27, 1, 2, 33, 67, 1, 0, 35, 1, 10, 1, 0, 0, 0], [21, 1, 3, 22, 135, 0, 0, 31, 1, 12, 1, 1, 2, 1], [30, 1, 2, 27, 132, 0, 0, 56, 0, 0, 0, 0, 0, 1], [9, 1, 3, 33, 71, 0, 0, 69, 0, 15, 0, 0, 0, 0], [24, 0, 2, 13, 133, 0, 0, 70, 0, 0, 0, 0, 0, 0], [26, 1, 3, 21, 32, 0, 2, 31, 1, 23, 1, 2, 2, 1], [24, 1, 1, 13, 103, 0, 2, 58, 0, 17, 1, 0, 0, 1], [15, 1, 1, 21, 89, 0, 0, 69, 0, 6, 0, 0, 0, 0], [14, 1, 1, 8, 55, 0, 0, 66, 0, 10, 2, 0, 2, 1], [18, 1, 2, 41, 26, 1, 0, 60, 0, 5, 0, 0, 2, 0], [10, 1, 1, 13, 86, 0, 0, 71, 0, 0, 0, 0, 2, 0], [22, 0, 1, 27, 109, 0, 2, 51, 0, 13, 1, 0, 0, 0], [23, 1, 3, 27, 20, 0, 0, 46, 0, 4, 1, 0, 1, 0], [33, 1, 3, 38, 104, 0, 2, 9, 1, 15, 1, 3, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "#1-B 1)\n",
    "#a_list = data_values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for i in range(len(a_list[0])):\n",
    "    temp=[]\n",
    "    for j in range(len(a_list)):\n",
    "        temp.append(a_list[j][i])\n",
    "    le.fit(temp)\n",
    "    list(le.classes_)\n",
    "    tempnum = le.transform(temp)\n",
    "    for j in range(len(a_list)):\n",
    "        a_list[j][i] = tempnum[j]\n",
    "a_list_enc = a_list\n",
    "\n",
    "print(a_list_enc)\n",
    "\n",
    "import pandas as pd\n",
    "df= pd.DataFrame(data=a_list_enc)\n",
    "df.to_csv('a_list_enc.csv',index=False,header=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36, 2, 4, 30, 38, 2, 3, 25, 2, 29, 3, 4, 3, 2], [33, 0, 2, 10, 142, 0, 2, 58, 0, 16, 1, 0, 2, 0], [23, 1, 1, 16, 84, 0, 0, 39, 0, 3, 0, 0, 2, 1], [30, 1, 3, 19, 86, 0, 0, 7, 1, 2, 1, 1, 2, 0], [38, 0, 1, 13, 92, 0, 2, 20, 1, 2, 0, 1, 0, 0], [31, 1, 3, 13, 11, 0, 0, 38, 0, 4, 0, 0, 2, 0], [22, 1, 2, 21, 79, 1, 2, 40, 1, 6, 1, 1, 1, 1], [25, 1, 3, 8, 64, 0, 2, 40, 1, 12, 1, 1, 2, 1], [26, 1, 3, 27, 108, 0, 2, 68, 0, 12, 1, 2, 2, 1], [29, 0, 3, 33, 139, 0, 2, 52, 0, 35, 1, 3, 2, 1], [25, 1, 3, 24, 60, 0, 0, 59, 0, 5, 1, 0, 2, 0], [19, 1, 3, 28, 52, 0, 2, 11, 1, 0, 0, 0, 2, 0], [10, 1, 2, 27, 61, 0, 2, 77, 0, 0, 0, 0, 0, 0], [27, 1, 0, 23, 60, 0, 0, 43, 0, 25, 1, 2, 0, 1], [23, 0, 3, 19, 115, 0, 2, 57, 0, 0, 0, 1, 0, 0], [37, 0, 3, 9, 2, 0, 0, 24, 0, 16, 1, 0, 0, 0], [12, 1, 3, 27, 122, 0, 0, 19, 1, 17, 1, 2, 2, 1], [19, 1, 3, 27, 29, 1, 2, 53, 1, 29, 2, 0, 2, 1], [30, 1, 0, 8, 37, 0, 2, 42, 1, 17, 1, 0, 0, 0], [6, 1, 0, 27, 26, 0, 0, 75, 1, 14, 0, 0, 2, 0], [33, 1, 3, 13, 55, 0, 2, 28, 1, 25, 1, 2, 2, 1], [14, 1, 1, 21, 69, 0, 2, 77, 0, 2, 1, 0, 0, 0], [9, 1, 3, 10, 115, 0, 0, 78, 0, 12, 1, 0, 0, 0], [13, 1, 3, 9, 30, 0, 0, 41, 0, 1, 0, 0, 0, 0], [20, 0, 1, 22, 105, 1, 2, 57, 1, 0, 0, 1, 0, 0], [14, 0, 2, 21, 97, 0, 0, 37, 0, 2, 0, 0, 0, 0], [12, 0, 3, 26, 67, 0, 2, 50, 1, 0, 1, 0, 0, 0], [17, 0, 2, 13, 110, 0, 2, 55, 0, 6, 0, 0, 0, 0], [24, 1, 2, 9, 56, 0, 2, 63, 0, 24, 1, 1, 2, 1], [37, 0, 2, 8, 88, 1, 2, 29, 0, 0, 0, 1, 0, 0], [23, 1, 2, 19, 55, 0, 2, 48, 0, 4, 1, 1, 2, 1], [32, 1, 3, 38, 54, 0, 2, 36, 0, 22, 0, 0, 1, 0], [3, 0, 2, 13, 41, 0, 0, 68, 0, 0, 0, 0, 0, 0], [25, 1, 3, 40, 129, 0, 2, 38, 1, 31, 2, 0, 2, 1], [16, 1, 3, 29, 27, 0, 2, 25, 1, 9, 1, 0, 2, 1], [14, 1, 3, 21, 79, 1, 2, 48, 1, 0, 0, 2, 2, 1], [27, 1, 3, 27, 33, 0, 2, 36, 1, 18, 0, 1, 2, 1], [25, 1, 0, 38, 95, 0, 2, 24, 0, 0, 0, 0, 0, 1], [8, 1, 2, 21, 13, 0, 0, 48, 0, 0, 0, 0, 0, 0], [14, 1, 3, 14, 48, 0, 2, 82, 0, 0, 0, 0, 0, 0], [6, 1, 3, 34, 49, 0, 0, 78, 0, 0, 0, 0, 2, 1], [28, 0, 3, 16, 35, 0, 0, 61, 0, 0, 0, 0, 0, 0], [10, 1, 2, 21, 59, 0, 0, 76, 1, 4, 0, 0, 0, 0], [12, 1, 1, 2, 24, 1, 0, 54, 0, 0, 0, 0, 2, 0], [25, 1, 2, 18, 44, 1, 0, 33, 0, 21, 1, 1, 1, 1], [24, 1, 2, 27, 37, 1, 2, 63, 0, 0, 0, 0, 0, 0], [15, 1, 2, 12, 2, 0, 2, 25, 0, 8, 0, 3, 0, 1], [10, 1, 3, 8, 24, 0, 2, 74, 0, 0, 0, 1, 0, 1], [32, 1, 1, 38, 70, 0, 0, 19, 1, 0, 1, 3, 1, 1], [31, 0, 3, 33, 51, 0, 2, 14, 0, 10, 1, 3, 2, 1], [8, 1, 3, 25, 124, 0, 0, 24, 1, 17, 1, 0, 1, 1], [18, 1, 1, 19, 31, 1, 0, 80, 0, 0, 0, 0, 0, 0], [31, 0, 2, 27, 141, 1, 2, 55, 0, 8, 0, 1, 0, 0], [29, 0, 1, 27, 22, 0, 0, 76, 0, 0, 0, 2, 0, 0], [11, 0, 1, 21, 60, 0, 2, 73, 0, 6, 1, 0, 0, 0], [7, 0, 1, 5, 25, 0, 0, 66, 0, 0, 0, 1, 0, 0], [27, 1, 3, 26, 5, 0, 2, 24, 1, 33, 1, 1, 0, 1], [26, 0, 2, 13, 12, 1, 0, 3, 0, 0, 0, 0, 0, 0], [25, 0, 3, 42, 73, 0, 0, 41, 1, 0, 1, 0, 0, 1], [28, 1, 1, 13, 100, 0, 2, 6, 0, 14, 1, 1, 2, 1], [23, 1, 2, 33, 0, 1, 0, 71, 0, 2, 0, 1, 2, 0], [17, 0, 3, 21, 117, 0, 0, 40, 1, 12, 1, 0, 2, 1], [10, 1, 2, 13, 52, 0, 0, 67, 0, 0, 0, 0, 0, 0], [26, 0, 0, 33, 65, 0, 0, 69, 0, 9, 0, 0, 0, 0], [29, 1, 0, 30, 59, 1, 2, 48, 0, 22, 2, 0, 1, 0], [23, 1, 3, 33, 98, 0, 2, 12, 1, 6, 1, 1, 1, 1], [17, 1, 3, 27, 84, 0, 2, 82, 1, 0, 0, 0, 0, 0], [24, 0, 1, 25, 126, 1, 2, 50, 0, 0, 0, 2, 0, 1], [10, 0, 2, 12, 66, 0, 0, 47, 0, 3, 1, 1, 0, 0], [13, 1, 2, 7, 67, 0, 0, 50, 0, 0, 0, 0, 0, 1], [27, 1, 3, 13, 83, 0, 0, 38, 1, 33, 1, 1, 2, 1], [23, 0, 3, 13, 136, 0, 0, 61, 1, 6, 0, 0, 0, 0], [36, 1, 1, 36, 69, 0, 2, 41, 0, 0, 0, 0, 0, 0], [39, 0, 2, 27, 24, 0, 1, 16, 0, 11, 1, 0, 0, 0], [33, 0, 3, 6, 49, 0, 0, 40, 0, 3, 0, 2, 0, 0], [11, 1, 3, 28, 121, 0, 2, 45, 1, 0, 1, 3, 2, 1], [11, 1, 3, 4, 34, 0, 2, 46, 1, 28, 1, 0, 0, 0], [5, 0, 2, 0, 26, 0, 0, 76, 0, 0, 0, 0, 0, 0], [8, 0, 2, 13, 35, 0, 0, 71, 0, 0, 1, 0, 0, 0], [22, 1, 1, 13, 62, 0, 0, 75, 0, 8, 0, 0, 0, 0], [24, 1, 3, 31, 44, 0, 0, 7, 0, 19, 1, 1, 2, 1], [2, 1, 3, 13, 25, 0, 0, 29, 1, 16, 1, 0, 2, 1], [24, 1, 3, 33, 93, 0, 2, 11, 1, 8, 0, 0, 2, 1], [7, 1, 2, 21, 40, 0, 2, 66, 0, 19, 1, 0, 0, 0], [23, 1, 3, 8, 28, 0, 0, 25, 1, 15, 1, 0, 1, 0], [8, 1, 0, 32, 68, 0, 2, 75, 0, 8, 0, 2, 0, 0], [28, 1, 1, 19, 34, 1, 2, 38, 0, 0, 0, 0, 0, 0], [25, 1, 0, 43, 93, 0, 2, 43, 0, 36, 2, 0, 2, 0], [7, 0, 1, 18, 118, 0, 0, 61, 0, 0, 0, 0, 0, 0], [16, 1, 3, 33, 67, 0, 2, 27, 0, 25, 1, 0, 2, 1], [25, 1, 1, 27, 47, 0, 0, 62, 1, 0, 0, 0, 0, 0], [27, 0, 3, 21, 131, 0, 2, 67, 0, 0, 0, 0, 0, 1], [20, 1, 3, 16, 89, 0, 2, 10, 1, 21, 1, 1, 2, 1], [20, 1, 3, 8, 32, 0, 2, 9, 1, 0, 1, 1, 0, 1], [18, 1, 3, 17, 38, 0, 0, 66, 0, 10, 0, 2, 2, 1], [13, 1, 3, 8, 97, 0, 2, 18, 1, 10, 1, 1, 0, 1], [32, 1, 3, 13, 114, 0, 2, 49, 0, 4, 1, 0, 0, 0], [24, 1, 3, 1, 60, 0, 0, 54, 0, 1, 0, 1, 2, 1], [30, 0, 2, 27, 123, 0, 0, 32, 0, 2, 0, 0, 2, 0], [16, 0, 1, 13, 68, 0, 0, 60, 0, 11, 0, 0, 0, 0], [10, 0, 2, 7, 1, 0, 0, 73, 0, 6, 1, 0, 0, 0], [33, 1, 3, 13, 63, 0, 0, 0, 0, 10, 1, 0, 0, 1], [15, 0, 3, 21, 92, 0, 0, 61, 0, 0, 0, 0, 0, 0], [23, 1, 3, 39, 106, 1, 2, 23, 0, 10, 1, 3, 2, 1], [29, 1, 3, 21, 77, 0, 2, 45, 0, 14, 1, 1, 2, 1], [14, 1, 3, 16, 96, 0, 2, 64, 0, 5, 1, 0, 2, 1], [17, 1, 2, 1, 48, 0, 0, 41, 1, 12, 1, 0, 0, 0], [26, 0, 3, 33, 81, 0, 2, 55, 0, 25, 1, 2, 2, 1], [25, 1, 3, 27, 11, 0, 0, 60, 1, 0, 0, 1, 2, 1], [11, 0, 1, 9, 3, 0, 0, 36, 0, 0, 1, 0, 0, 0], [21, 0, 3, 44, 130, 0, 1, 17, 1, 31, 1, 0, 0, 1], [7, 1, 1, 8, 61, 0, 0, 51, 0, 0, 0, 0, 0, 0], [26, 0, 3, 37, 117, 0, 2, 59, 0, 0, 0, 0, 0, 1], [20, 0, 2, 24, 116, 1, 0, 68, 0, 0, 0, 0, 0, 0], [8, 1, 1, 13, 110, 0, 0, 60, 0, 0, 0, 0, 0, 0], [15, 0, 1, 23, 94, 0, 0, 60, 0, 0, 1, 0, 0, 0], [12, 1, 3, 13, 73, 0, 2, 42, 0, 8, 0, 0, 2, 1], [22, 0, 3, 46, 105, 1, 2, 32, 1, 35, 2, 2, 2, 1], [32, 0, 0, 33, 52, 0, 0, 14, 0, 25, 2, 0, 0, 0], [22, 1, 3, 21, 102, 1, 2, 6, 1, 16, 2, 0, 2, 1], [15, 1, 2, 13, 19, 0, 0, 37, 0, 19, 1, 3, 2, 1], [20, 1, 3, 14, 104, 0, 2, 16, 1, 30, 1, 2, 0, 1], [23, 1, 3, 34, 96, 0, 0, 1, 1, 12, 1, 1, 2, 1], [31, 0, 2, 38, 137, 0, 2, 49, 0, 8, 0, 0, 0, 0], [20, 1, 2, 17, 95, 0, 2, 50, 0, 5, 2, 1, 0, 0], [20, 0, 2, 38, 28, 0, 0, 61, 0, 0, 0, 1, 0, 0], [28, 1, 3, 13, 90, 0, 0, 5, 1, 17, 1, 2, 2, 1], [18, 0, 2, 25, 23, 0, 2, 67, 0, 1, 1, 0, 0, 0], [18, 1, 1, 23, 28, 0, 0, 56, 0, 8, 0, 1, 0, 0], [26, 1, 3, 11, 56, 1, 0, 58, 1, 14, 0, 2, 2, 1], [29, 0, 3, 7, 92, 0, 0, 67, 1, 17, 1, 2, 0, 1], [32, 1, 3, 9, 38, 0, 2, 31, 1, 1, 0, 1, 0, 1], [8, 1, 3, 27, 52, 0, 0, 75, 0, 0, 0, 0, 0, 0], [30, 1, 3, 13, 70, 0, 2, 3, 1, 21, 2, 1, 0, 1], [20, 1, 2, 33, 58, 0, 2, 63, 0, 16, 0, 0, 2, 0], [12, 0, 2, 28, 11, 0, 2, 58, 1, 14, 2, 0, 0, 0], [33, 0, 2, 34, 99, 0, 0, 70, 0, 0, 0, 1, 0, 0], [22, 1, 3, 17, 73, 1, 2, 42, 1, 12, 1, 1, 0, 1], [1, 0, 1, 12, 36, 0, 0, 86, 0, 7, 0, 0, 0, 0], [23, 1, 3, 22, 33, 0, 0, 66, 1, 0, 0, 0, 2, 0], [30, 1, 3, 30, 38, 0, 2, 31, 0, 19, 1, 2, 1, 1], [25, 1, 3, 26, 94, 0, 2, 79, 0, 0, 0, 0, 0, 0], [16, 1, 2, 27, 59, 0, 0, 61, 0, 6, 1, 1, 2, 1], [17, 1, 0, 17, 39, 0, 2, 24, 1, 14, 0, 1, 0, 0], [20, 1, 1, 45, 102, 0, 2, 88, 0, 0, 0, 1, 2, 1], [19, 1, 3, 15, 101, 0, 0, 2, 1, 19, 1, 2, 2, 1], [18, 1, 3, 9, 56, 0, 0, 58, 0, 0, 0, 1, 0, 1], [6, 1, 3, 8, 6, 0, 2, 14, 1, 19, 1, 0, 2, 1], [24, 1, 2, 22, 50, 0, 2, 71, 0, 30, 0, 2, 2, 1], [7, 0, 2, 9, 91, 0, 2, 70, 1, 0, 0, 0, 0, 0], [7, 1, 2, 9, 74, 0, 0, 76, 0, 0, 0, 0, 0, 0], [16, 0, 2, 13, 45, 0, 0, 56, 0, 16, 1, 0, 0, 0], [20, 0, 2, 7, 90, 0, 2, 65, 0, 0, 0, 0, 0, 0], [30, 0, 3, 21, 115, 0, 0, 21, 0, 19, 1, 2, 0, 0], [17, 0, 2, 21, 79, 0, 2, 47, 0, 5, 0, 0, 0, 0], [12, 0, 1, 5, 30, 0, 0, 70, 0, 0, 0, 0, 0, 0], [21, 1, 3, 27, 43, 0, 0, 11, 1, 37, 2, 0, 2, 1], [11, 1, 1, 19, 120, 0, 2, 68, 0, 0, 0, 0, 0, 0], [22, 1, 0, 13, 21, 0, 2, 60, 0, 18, 1, 0, 2, 0], [32, 0, 3, 43, 54, 1, 0, 63, 1, 10, 1, 2, 2, 1], [4, 1, 0, 13, 57, 0, 0, 79, 1, 34, 1, 0, 2, 1], [28, 0, 3, 33, 68, 0, 0, 52, 1, 14, 1, 0, 0, 1], [21, 1, 1, 21, 85, 0, 0, 53, 0, 0, 0, 0, 0, 0], [24, 1, 3, 19, 82, 0, 2, 29, 1, 28, 1, 2, 2, 1], [9, 1, 3, 8, 37, 0, 0, 59, 0, 0, 0, 0, 2, 0], [30, 0, 3, 44, 128, 0, 0, 52, 1, 0, 0, 0, 0, 0], [16, 0, 3, 8, 77, 0, 2, 57, 0, 0, 0, 0, 0, 0], [19, 1, 2, 21, 24, 1, 2, 50, 0, 12, 2, 0, 0, 0], [11, 0, 3, 26, 62, 0, 2, 50, 1, 2, 1, 0, 0, 0], [31, 1, 0, 26, 101, 1, 2, 72, 0, 14, 1, 1, 0, 1], [35, 1, 0, 38, 60, 1, 2, 30, 0, 1, 1, 1, 0, 0], [35, 1, 2, 27, 77, 0, 2, 44, 0, 19, 1, 3, 2, 1], [33, 1, 3, 1, 112, 0, 2, 24, 1, 9, 1, 2, 0, 1], [34, 0, 2, 13, 37, 0, 2, 15, 0, 15, 1, 0, 0, 0], [1, 1, 0, 12, 14, 0, 2, 72, 0, 0, 0, 0, 0, 0], [28, 0, 3, 26, 109, 1, 0, 8, 0, 18, 1, 3, 0, 1], [17, 1, 3, 27, 111, 0, 0, 21, 1, 36, 1, 3, 2, 1], [12, 1, 2, 33, 57, 0, 0, 45, 0, 33, 1, 0, 0, 1], [33, 1, 3, 17, 77, 1, 0, 61, 0, 2, 1, 2, 2, 1], [16, 1, 2, 20, 23, 0, 0, 61, 0, 0, 0, 0, 0, 0], [8, 1, 2, 13, 65, 1, 0, 87, 0, 8, 2, 0, 2, 0], [22, 0, 3, 23, 140, 0, 2, 48, 1, 18, 1, 2, 2, 1], [7, 1, 3, 8, 8, 0, 2, 56, 0, 0, 0, 0, 2, 1], [8, 0, 3, 3, 88, 0, 2, 21, 0, 6, 1, 0, 0, 0], [19, 1, 2, 21, 70, 1, 2, 71, 0, 0, 0, 3, 0, 0], [9, 1, 2, 21, 124, 0, 0, 60, 0, 18, 0, 1, 0, 0], [22, 1, 3, 22, 16, 0, 2, 7, 1, 20, 1, 1, 1, 1], [18, 1, 3, 7, 59, 1, 0, 45, 0, 1, 0, 3, 2, 0], [28, 0, 3, 27, 138, 0, 2, 55, 0, 12, 1, 0, 0, 0], [36, 1, 2, 38, 92, 0, 0, 12, 1, 27, 1, 1, 2, 1], [20, 1, 3, 27, 64, 0, 0, 58, 0, 12, 0, 0, 0, 0], [36, 1, 3, 30, 9, 0, 0, 24, 1, 25, 2, 0, 2, 1], [20, 1, 1, 7, 121, 0, 0, 54, 0, 0, 0, 0, 2, 0], [2, 1, 3, 18, 101, 0, 2, 54, 1, 0, 0, 0, 2, 1], [14, 1, 2, 16, 78, 1, 0, 73, 0, 0, 0, 2, 0, 0], [21, 0, 1, 24, 74, 0, 2, 59, 0, 14, 1, 0, 0, 0], [24, 0, 3, 1, 72, 0, 2, 21, 0, 10, 1, 0, 0, 0], [20, 0, 2, 8, 40, 0, 0, 56, 0, 16, 1, 0, 0, 0], [35, 0, 0, 27, 64, 0, 0, 49, 0, 17, 0, 2, 0, 0], [40, 1, 3, 17, 116, 0, 2, 60, 1, 0, 0, 3, 0, 1], [34, 1, 2, 12, 99, 0, 0, 49, 0, 10, 0, 1, 2, 0], [24, 1, 3, 17, 113, 0, 2, 69, 0, 0, 0, 2, 2, 1], [26, 1, 3, 17, 81, 0, 2, 39, 1, 26, 1, 1, 2, 1], [17, 1, 3, 27, 112, 0, 0, 71, 1, 16, 0, 0, 2, 1], [21, 1, 3, 38, 106, 0, 2, 43, 1, 8, 1, 1, 2, 1], [18, 1, 0, 34, 111, 1, 0, 75, 0, 12, 1, 0, 2, 0], [26, 0, 2, 3, 125, 0, 0, 58, 0, 0, 0, 1, 0, 0], [24, 1, 2, 5, 65, 0, 2, 52, 1, 6, 1, 0, 2, 0], [30, 1, 2, 17, 121, 0, 0, 30, 1, 17, 1, 0, 2, 1], [3, 1, 2, 21, 74, 0, 0, 83, 0, 32, 2, 0, 0, 0], [25, 1, 0, 40, 105, 0, 2, 57, 0, 2, 1, 0, 2, 1], [17, 1, 2, 17, 69, 1, 2, 64, 0, 23, 1, 0, 0, 0], [9, 0, 2, 14, 39, 0, 0, 63, 0, 2, 1, 0, 0, 0], [24, 1, 3, 19, 42, 0, 2, 30, 1, 21, 1, 3, 2, 1], [0, 1, 1, 21, 30, 0, 2, 89, 0, 0, 0, 0, 0, 0], [7, 0, 1, 21, 30, 0, 2, 70, 0, 14, 0, 0, 0, 0], [29, 0, 2, 24, 75, 0, 2, 70, 0, 0, 0, 0, 0, 0], [17, 1, 2, 0, 53, 0, 0, 52, 1, 0, 0, 1, 2, 0], [20, 1, 2, 13, 81, 0, 2, 45, 0, 4, 1, 0, 2, 0], [10, 1, 1, 13, 46, 0, 0, 68, 0, 0, 0, 0, 0, 0], [20, 1, 3, 8, 64, 0, 0, 25, 1, 26, 1, 1, 2, 1], [31, 1, 3, 24, 77, 0, 2, 26, 0, 26, 1, 1, 2, 1], [23, 1, 2, 33, 7, 0, 0, 72, 0, 16, 0, 0, 0, 0], [29, 1, 3, 21, 131, 1, 2, 31, 1, 17, 0, 3, 2, 1], [2, 0, 3, 26, 15, 0, 0, 79, 0, 14, 0, 0, 0, 0], [7, 1, 1, 24, 29, 0, 0, 31, 0, 0, 1, 0, 1, 0], [28, 0, 2, 21, 86, 0, 0, 4, 0, 12, 1, 1, 2, 1], [9, 0, 3, 22, 134, 1, 2, 34, 1, 28, 1, 0, 2, 1], [24, 0, 0, 33, 102, 1, 2, 60, 0, 10, 0, 0, 0, 0], [18, 1, 0, 12, 18, 0, 2, 85, 0, 0, 1, 0, 1, 0], [27, 0, 3, 30, 119, 0, 2, 44, 1, 10, 1, 0, 2, 1], [5, 1, 3, 12, 45, 0, 0, 38, 0, 12, 1, 0, 2, 1], [11, 1, 3, 10, 83, 0, 2, 81, 0, 0, 0, 0, 0, 0], [18, 1, 3, 19, 78, 0, 0, 59, 1, 0, 0, 1, 2, 1], [28, 1, 2, 21, 57, 0, 0, 44, 0, 17, 1, 3, 2, 0], [28, 0, 3, 38, 4, 0, 2, 43, 0, 38, 2, 3, 2, 1], [19, 0, 3, 26, 60, 0, 2, 58, 0, 0, 0, 0, 0, 0], [9, 1, 3, 13, 11, 0, 2, 19, 1, 24, 1, 0, 2, 1], [13, 1, 2, 26, 80, 0, 2, 54, 0, 0, 0, 0, 0, 0], [18, 1, 1, 13, 128, 0, 0, 70, 0, 2, 0, 0, 0, 0], [34, 1, 2, 44, 96, 1, 2, 48, 1, 16, 1, 0, 2, 1], [5, 1, 2, 27, 127, 0, 2, 79, 0, 0, 0, 0, 0, 0], [19, 0, 3, 21, 87, 0, 2, 41, 0, 4, 1, 0, 0, 0], [28, 0, 3, 27, 91, 0, 2, 58, 0, 33, 2, 2, 0, 1], [17, 0, 2, 27, 120, 0, 2, 40, 0, 15, 0, 1, 0, 0], [26, 1, 3, 21, 76, 0, 0, 42, 1, 14, 0, 1, 2, 1], [31, 1, 3, 8, 72, 0, 2, 56, 0, 6, 0, 2, 1, 1], [31, 0, 2, 35, 92, 0, 0, 46, 0, 8, 0, 0, 0, 0], [26, 1, 2, 27, 17, 0, 2, 53, 0, 28, 1, 0, 0, 1], [26, 1, 3, 30, 101, 0, 2, 40, 1, 26, 1, 2, 2, 1], [20, 1, 3, 13, 19, 0, 0, 13, 0, 14, 1, 1, 2, 1], [10, 1, 1, 21, 45, 0, 2, 84, 0, 0, 0, 0, 0, 0], [10, 1, 3, 9, 107, 0, 2, 51, 0, 0, 0, 1, 0, 1], [17, 1, 2, 8, 10, 0, 0, 22, 0, 6, 0, 0, 0, 0], [25, 1, 2, 33, 38, 1, 0, 55, 0, 16, 0, 0, 0, 0], [37, 0, 1, 38, 114, 0, 0, 60, 0, 4, 0, 2, 0, 0], [27, 1, 2, 33, 67, 1, 0, 35, 1, 10, 1, 0, 0, 0], [21, 1, 3, 22, 135, 0, 0, 31, 1, 12, 1, 1, 2, 1], [30, 1, 2, 27, 132, 0, 0, 56, 0, 0, 0, 0, 0, 1], [9, 1, 3, 33, 71, 0, 0, 69, 0, 15, 0, 0, 0, 0], [24, 0, 2, 13, 133, 0, 0, 70, 0, 0, 0, 0, 0, 0], [26, 1, 3, 21, 32, 0, 2, 31, 1, 23, 1, 2, 2, 1], [24, 1, 1, 13, 103, 0, 2, 58, 0, 17, 1, 0, 0, 1], [15, 1, 1, 21, 89, 0, 0, 69, 0, 6, 0, 0, 0, 0], [14, 1, 1, 8, 55, 0, 0, 66, 0, 10, 2, 0, 2, 1], [18, 1, 2, 41, 26, 1, 0, 60, 0, 5, 0, 0, 2, 0], [10, 1, 1, 13, 86, 0, 0, 71, 0, 0, 0, 0, 2, 0], [22, 0, 1, 27, 109, 0, 2, 51, 0, 13, 1, 0, 0, 0], [23, 1, 3, 27, 20, 0, 0, 46, 0, 4, 1, 0, 1, 0], [33, 1, 3, 38, 104, 0, 2, 9, 1, 15, 1, 3, 0, 1]]\n",
      "[[0.9        1.         1.         ... 1.         1.         1.        ]\n",
      " [0.825      0.         0.5        ... 0.         0.66666667 0.        ]\n",
      " [0.575      0.5        0.25       ... 0.         0.66666667 0.5       ]\n",
      " ...\n",
      " [0.55       0.         0.25       ... 0.         0.         0.        ]\n",
      " [0.575      0.5        0.75       ... 0.         0.33333333 0.        ]\n",
      " [0.825      0.5        0.75       ... 0.75       0.         0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "#2 1)\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "min_max_scaler.fit(a_list)\n",
    "print(a_list)\n",
    "print(min_max_scaler.transform(a_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.74052305  2.7829491   1.9111156  ...  3.48922751  2.2449413\n",
      "   3.07482048]\n",
      " [ 1.40493065 -1.43837818 -0.1864503  ... -0.70717083  1.20881455\n",
      "  -0.88795532]\n",
      " [ 0.28628932  0.67228546 -1.23523326 ... -0.70717083  1.20881455\n",
      "   1.09343258]\n",
      " ...\n",
      " [ 0.17442519 -1.43837818 -1.23523326 ... -0.70717083 -0.86343896\n",
      "  -0.88795532]\n",
      " [ 0.28628932  0.67228546  0.86233265 ... -0.70717083  0.17268779\n",
      "  -0.88795532]\n",
      " [ 1.40493065  0.67228546  0.86233265 ...  2.44012792 -0.86343896\n",
      "   1.09343258]]\n"
     ]
    }
   ],
   "source": [
    "#2 2)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(a_list_enc)\n",
    "a_list_enc_norm = scaler.transform(a_list_enc)\n",
    "print(a_list_enc_norm)\n",
    "\n",
    "import pandas as pd\n",
    "df= pd.DataFrame(data=a_list_enc_norm)\n",
    "df.to_csv('a_list_enc_norm.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 1)\n",
    "\n",
    "X_data=[]\n",
    "Y_data=[]\n",
    "\n",
    "for i in range(len(a_list_enc_norm)):\n",
    "    X_data.append(a_list_enc_norm[i][:len(a_list_enc_norm[0])-1])\n",
    "    Y_data.append(a_list_enc_norm[i][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-42f35726c746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"\"\"\n\u001b[1;32m    994\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 995\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    323\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)"
     ]
    }
   ],
   "source": [
    "#4 1) a\n",
    "\n",
    "no_of_node = []\n",
    "accuracy = []\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(3, ), max_iter=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy.append(accuracy_score(Y_test, predictions))\n",
    "\n",
    "\n",
    "print(classification_report(Y_test, predictions))\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(accuracy_score(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-94b977c0eebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#clf.fit(X_train, Y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"\"\"\n\u001b[1;32m    994\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 995\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    323\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)"
     ]
    }
   ],
   "source": [
    "#b\n",
    "clf = MLPClassifier(hidden_layer_sizes=(3,3, ), max_iter=1500)\n",
    "clf.fit(X_train, Y_train)\n",
    "predictions =clf.predict(X_test)\n",
    "accuracy.append(accuracy_score(Y_test, predictions))\n",
    "#clf.fit(X_train, Y_train)\n",
    "#predictions =clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-52f9b4ed05a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#4 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"\"\"\n\u001b[1;32m    994\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 995\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    323\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)"
     ]
    }
   ],
   "source": [
    "#4 2)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(3,3,3),max_iter=2000)\n",
    "clf.fit(X_train,Y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accpp.append(accuracy_score(Y_test, predictions))\n",
    "\n",
    "print(accuracy_score(Y_test, predictions))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "no_of_node = [1,2,3]\n",
    "plt.plot(no_of_node, accuracy,marker='.')\n",
    "plt.xlabel('no_of_node')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Hidden layer/node vs Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-142e9bf0e0df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maccur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'identity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0maccur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \"\"\"\n\u001b[1;32m    994\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[0;32m--> 995\u001b[0;31m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    323\u001b[0m                              hidden_layer_sizes)\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, y, incremental)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mincremental\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_label_binarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([-0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258,  3.07482048,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258, -0.88795532, -0.88795532,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n        1.09343258,  1.09343258,  1.09343258,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n        1.09343258, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532, -0.88795532, -0.88795532,  1.09343258,  1.09343258,\n       -0.88795532,  1.09343258, -0.88795532,  1.09343258, -0.88795532,\n       -0.88795532,  1.09343258,  1.09343258, -0.88795532, -0.88795532,\n        1.09343258, -0.88795532,  1.09343258, -0.88795532, -0.88795532,\n       -0.88795532, -0.88795532,  1.09343258,  1.09343258,  1.09343258,\n       -0.88795532, -0.88795532, -0.88795532, -0.88795532]),)"
     ]
    }
   ],
   "source": [
    "#4-3\n",
    "\n",
    "accur = []\n",
    "clf = MLPClassifier(activation='identity',hidden_layer_sizes=(3,3,3),max_iter=2000)\n",
    "clf.fit(X_train,Y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "accur.append(accuracy_score(Y_test,predictions))\n",
    "\n",
    "print(accur)\n",
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36, 2, 4, 30, 38, 2, 3, 25, 2, 29, 3, 4, 3, 2], [33, 0, 2, 10, 142, 0, 2, 58, 0, 16, 1, 0, 2, 0], [23, 1, 1, 16, 84, 0, 0, 39, 0, 3, 0, 0, 2, 1], [30, 1, 3, 19, 86, 0, 0, 7, 1, 2, 1, 1, 2, 0], [38, 0, 1, 13, 92, 0, 2, 20, 1, 2, 0, 1, 0, 0], [31, 1, 3, 13, 11, 0, 0, 38, 0, 4, 0, 0, 2, 0], [22, 1, 2, 21, 79, 1, 2, 40, 1, 6, 1, 1, 1, 1], [25, 1, 3, 8, 64, 0, 2, 40, 1, 12, 1, 1, 2, 1], [26, 1, 3, 27, 108, 0, 2, 68, 0, 12, 1, 2, 2, 1], [29, 0, 3, 33, 139, 0, 2, 52, 0, 35, 1, 3, 2, 1], [25, 1, 3, 24, 60, 0, 0, 59, 0, 5, 1, 0, 2, 0], [19, 1, 3, 28, 52, 0, 2, 11, 1, 0, 0, 0, 2, 0], [10, 1, 2, 27, 61, 0, 2, 77, 0, 0, 0, 0, 0, 0], [27, 1, 0, 23, 60, 0, 0, 43, 0, 25, 1, 2, 0, 1], [23, 0, 3, 19, 115, 0, 2, 57, 0, 0, 0, 1, 0, 0], [37, 0, 3, 9, 2, 0, 0, 24, 0, 16, 1, 0, 0, 0], [12, 1, 3, 27, 122, 0, 0, 19, 1, 17, 1, 2, 2, 1], [19, 1, 3, 27, 29, 1, 2, 53, 1, 29, 2, 0, 2, 1], [30, 1, 0, 8, 37, 0, 2, 42, 1, 17, 1, 0, 0, 0], [6, 1, 0, 27, 26, 0, 0, 75, 1, 14, 0, 0, 2, 0], [33, 1, 3, 13, 55, 0, 2, 28, 1, 25, 1, 2, 2, 1], [14, 1, 1, 21, 69, 0, 2, 77, 0, 2, 1, 0, 0, 0], [9, 1, 3, 10, 115, 0, 0, 78, 0, 12, 1, 0, 0, 0], [13, 1, 3, 9, 30, 0, 0, 41, 0, 1, 0, 0, 0, 0], [20, 0, 1, 22, 105, 1, 2, 57, 1, 0, 0, 1, 0, 0], [14, 0, 2, 21, 97, 0, 0, 37, 0, 2, 0, 0, 0, 0], [12, 0, 3, 26, 67, 0, 2, 50, 1, 0, 1, 0, 0, 0], [17, 0, 2, 13, 110, 0, 2, 55, 0, 6, 0, 0, 0, 0], [24, 1, 2, 9, 56, 0, 2, 63, 0, 24, 1, 1, 2, 1], [37, 0, 2, 8, 88, 1, 2, 29, 0, 0, 0, 1, 0, 0], [23, 1, 2, 19, 55, 0, 2, 48, 0, 4, 1, 1, 2, 1], [32, 1, 3, 38, 54, 0, 2, 36, 0, 22, 0, 0, 1, 0], [3, 0, 2, 13, 41, 0, 0, 68, 0, 0, 0, 0, 0, 0], [25, 1, 3, 40, 129, 0, 2, 38, 1, 31, 2, 0, 2, 1], [16, 1, 3, 29, 27, 0, 2, 25, 1, 9, 1, 0, 2, 1], [14, 1, 3, 21, 79, 1, 2, 48, 1, 0, 0, 2, 2, 1], [27, 1, 3, 27, 33, 0, 2, 36, 1, 18, 0, 1, 2, 1], [25, 1, 0, 38, 95, 0, 2, 24, 0, 0, 0, 0, 0, 1], [8, 1, 2, 21, 13, 0, 0, 48, 0, 0, 0, 0, 0, 0], [14, 1, 3, 14, 48, 0, 2, 82, 0, 0, 0, 0, 0, 0], [6, 1, 3, 34, 49, 0, 0, 78, 0, 0, 0, 0, 2, 1], [28, 0, 3, 16, 35, 0, 0, 61, 0, 0, 0, 0, 0, 0], [10, 1, 2, 21, 59, 0, 0, 76, 1, 4, 0, 0, 0, 0], [12, 1, 1, 2, 24, 1, 0, 54, 0, 0, 0, 0, 2, 0], [25, 1, 2, 18, 44, 1, 0, 33, 0, 21, 1, 1, 1, 1], [24, 1, 2, 27, 37, 1, 2, 63, 0, 0, 0, 0, 0, 0], [15, 1, 2, 12, 2, 0, 2, 25, 0, 8, 0, 3, 0, 1], [10, 1, 3, 8, 24, 0, 2, 74, 0, 0, 0, 1, 0, 1], [32, 1, 1, 38, 70, 0, 0, 19, 1, 0, 1, 3, 1, 1], [31, 0, 3, 33, 51, 0, 2, 14, 0, 10, 1, 3, 2, 1], [8, 1, 3, 25, 124, 0, 0, 24, 1, 17, 1, 0, 1, 1], [18, 1, 1, 19, 31, 1, 0, 80, 0, 0, 0, 0, 0, 0], [31, 0, 2, 27, 141, 1, 2, 55, 0, 8, 0, 1, 0, 0], [29, 0, 1, 27, 22, 0, 0, 76, 0, 0, 0, 2, 0, 0], [11, 0, 1, 21, 60, 0, 2, 73, 0, 6, 1, 0, 0, 0], [7, 0, 1, 5, 25, 0, 0, 66, 0, 0, 0, 1, 0, 0], [27, 1, 3, 26, 5, 0, 2, 24, 1, 33, 1, 1, 0, 1], [26, 0, 2, 13, 12, 1, 0, 3, 0, 0, 0, 0, 0, 0], [25, 0, 3, 42, 73, 0, 0, 41, 1, 0, 1, 0, 0, 1], [28, 1, 1, 13, 100, 0, 2, 6, 0, 14, 1, 1, 2, 1], [23, 1, 2, 33, 0, 1, 0, 71, 0, 2, 0, 1, 2, 0], [17, 0, 3, 21, 117, 0, 0, 40, 1, 12, 1, 0, 2, 1], [10, 1, 2, 13, 52, 0, 0, 67, 0, 0, 0, 0, 0, 0], [26, 0, 0, 33, 65, 0, 0, 69, 0, 9, 0, 0, 0, 0], [29, 1, 0, 30, 59, 1, 2, 48, 0, 22, 2, 0, 1, 0], [23, 1, 3, 33, 98, 0, 2, 12, 1, 6, 1, 1, 1, 1], [17, 1, 3, 27, 84, 0, 2, 82, 1, 0, 0, 0, 0, 0], [24, 0, 1, 25, 126, 1, 2, 50, 0, 0, 0, 2, 0, 1], [10, 0, 2, 12, 66, 0, 0, 47, 0, 3, 1, 1, 0, 0], [13, 1, 2, 7, 67, 0, 0, 50, 0, 0, 0, 0, 0, 1], [27, 1, 3, 13, 83, 0, 0, 38, 1, 33, 1, 1, 2, 1], [23, 0, 3, 13, 136, 0, 0, 61, 1, 6, 0, 0, 0, 0], [36, 1, 1, 36, 69, 0, 2, 41, 0, 0, 0, 0, 0, 0], [39, 0, 2, 27, 24, 0, 1, 16, 0, 11, 1, 0, 0, 0], [33, 0, 3, 6, 49, 0, 0, 40, 0, 3, 0, 2, 0, 0], [11, 1, 3, 28, 121, 0, 2, 45, 1, 0, 1, 3, 2, 1], [11, 1, 3, 4, 34, 0, 2, 46, 1, 28, 1, 0, 0, 0], [5, 0, 2, 0, 26, 0, 0, 76, 0, 0, 0, 0, 0, 0], [8, 0, 2, 13, 35, 0, 0, 71, 0, 0, 1, 0, 0, 0], [22, 1, 1, 13, 62, 0, 0, 75, 0, 8, 0, 0, 0, 0], [24, 1, 3, 31, 44, 0, 0, 7, 0, 19, 1, 1, 2, 1], [2, 1, 3, 13, 25, 0, 0, 29, 1, 16, 1, 0, 2, 1], [24, 1, 3, 33, 93, 0, 2, 11, 1, 8, 0, 0, 2, 1], [7, 1, 2, 21, 40, 0, 2, 66, 0, 19, 1, 0, 0, 0], [23, 1, 3, 8, 28, 0, 0, 25, 1, 15, 1, 0, 1, 0], [8, 1, 0, 32, 68, 0, 2, 75, 0, 8, 0, 2, 0, 0], [28, 1, 1, 19, 34, 1, 2, 38, 0, 0, 0, 0, 0, 0], [25, 1, 0, 43, 93, 0, 2, 43, 0, 36, 2, 0, 2, 0], [7, 0, 1, 18, 118, 0, 0, 61, 0, 0, 0, 0, 0, 0], [16, 1, 3, 33, 67, 0, 2, 27, 0, 25, 1, 0, 2, 1], [25, 1, 1, 27, 47, 0, 0, 62, 1, 0, 0, 0, 0, 0], [27, 0, 3, 21, 131, 0, 2, 67, 0, 0, 0, 0, 0, 1], [20, 1, 3, 16, 89, 0, 2, 10, 1, 21, 1, 1, 2, 1], [20, 1, 3, 8, 32, 0, 2, 9, 1, 0, 1, 1, 0, 1], [18, 1, 3, 17, 38, 0, 0, 66, 0, 10, 0, 2, 2, 1], [13, 1, 3, 8, 97, 0, 2, 18, 1, 10, 1, 1, 0, 1], [32, 1, 3, 13, 114, 0, 2, 49, 0, 4, 1, 0, 0, 0], [24, 1, 3, 1, 60, 0, 0, 54, 0, 1, 0, 1, 2, 1], [30, 0, 2, 27, 123, 0, 0, 32, 0, 2, 0, 0, 2, 0], [16, 0, 1, 13, 68, 0, 0, 60, 0, 11, 0, 0, 0, 0], [10, 0, 2, 7, 1, 0, 0, 73, 0, 6, 1, 0, 0, 0], [33, 1, 3, 13, 63, 0, 0, 0, 0, 10, 1, 0, 0, 1], [15, 0, 3, 21, 92, 0, 0, 61, 0, 0, 0, 0, 0, 0], [23, 1, 3, 39, 106, 1, 2, 23, 0, 10, 1, 3, 2, 1], [29, 1, 3, 21, 77, 0, 2, 45, 0, 14, 1, 1, 2, 1], [14, 1, 3, 16, 96, 0, 2, 64, 0, 5, 1, 0, 2, 1], [17, 1, 2, 1, 48, 0, 0, 41, 1, 12, 1, 0, 0, 0], [26, 0, 3, 33, 81, 0, 2, 55, 0, 25, 1, 2, 2, 1], [25, 1, 3, 27, 11, 0, 0, 60, 1, 0, 0, 1, 2, 1], [11, 0, 1, 9, 3, 0, 0, 36, 0, 0, 1, 0, 0, 0], [21, 0, 3, 44, 130, 0, 1, 17, 1, 31, 1, 0, 0, 1], [7, 1, 1, 8, 61, 0, 0, 51, 0, 0, 0, 0, 0, 0], [26, 0, 3, 37, 117, 0, 2, 59, 0, 0, 0, 0, 0, 1], [20, 0, 2, 24, 116, 1, 0, 68, 0, 0, 0, 0, 0, 0], [8, 1, 1, 13, 110, 0, 0, 60, 0, 0, 0, 0, 0, 0], [15, 0, 1, 23, 94, 0, 0, 60, 0, 0, 1, 0, 0, 0], [12, 1, 3, 13, 73, 0, 2, 42, 0, 8, 0, 0, 2, 1], [22, 0, 3, 46, 105, 1, 2, 32, 1, 35, 2, 2, 2, 1], [32, 0, 0, 33, 52, 0, 0, 14, 0, 25, 2, 0, 0, 0], [22, 1, 3, 21, 102, 1, 2, 6, 1, 16, 2, 0, 2, 1], [15, 1, 2, 13, 19, 0, 0, 37, 0, 19, 1, 3, 2, 1], [20, 1, 3, 14, 104, 0, 2, 16, 1, 30, 1, 2, 0, 1], [23, 1, 3, 34, 96, 0, 0, 1, 1, 12, 1, 1, 2, 1], [31, 0, 2, 38, 137, 0, 2, 49, 0, 8, 0, 0, 0, 0], [20, 1, 2, 17, 95, 0, 2, 50, 0, 5, 2, 1, 0, 0], [20, 0, 2, 38, 28, 0, 0, 61, 0, 0, 0, 1, 0, 0], [28, 1, 3, 13, 90, 0, 0, 5, 1, 17, 1, 2, 2, 1], [18, 0, 2, 25, 23, 0, 2, 67, 0, 1, 1, 0, 0, 0], [18, 1, 1, 23, 28, 0, 0, 56, 0, 8, 0, 1, 0, 0], [26, 1, 3, 11, 56, 1, 0, 58, 1, 14, 0, 2, 2, 1], [29, 0, 3, 7, 92, 0, 0, 67, 1, 17, 1, 2, 0, 1], [32, 1, 3, 9, 38, 0, 2, 31, 1, 1, 0, 1, 0, 1], [8, 1, 3, 27, 52, 0, 0, 75, 0, 0, 0, 0, 0, 0], [30, 1, 3, 13, 70, 0, 2, 3, 1, 21, 2, 1, 0, 1], [20, 1, 2, 33, 58, 0, 2, 63, 0, 16, 0, 0, 2, 0], [12, 0, 2, 28, 11, 0, 2, 58, 1, 14, 2, 0, 0, 0], [33, 0, 2, 34, 99, 0, 0, 70, 0, 0, 0, 1, 0, 0], [22, 1, 3, 17, 73, 1, 2, 42, 1, 12, 1, 1, 0, 1], [1, 0, 1, 12, 36, 0, 0, 86, 0, 7, 0, 0, 0, 0], [23, 1, 3, 22, 33, 0, 0, 66, 1, 0, 0, 0, 2, 0], [30, 1, 3, 30, 38, 0, 2, 31, 0, 19, 1, 2, 1, 1], [25, 1, 3, 26, 94, 0, 2, 79, 0, 0, 0, 0, 0, 0], [16, 1, 2, 27, 59, 0, 0, 61, 0, 6, 1, 1, 2, 1], [17, 1, 0, 17, 39, 0, 2, 24, 1, 14, 0, 1, 0, 0], [20, 1, 1, 45, 102, 0, 2, 88, 0, 0, 0, 1, 2, 1], [19, 1, 3, 15, 101, 0, 0, 2, 1, 19, 1, 2, 2, 1], [18, 1, 3, 9, 56, 0, 0, 58, 0, 0, 0, 1, 0, 1], [6, 1, 3, 8, 6, 0, 2, 14, 1, 19, 1, 0, 2, 1], [24, 1, 2, 22, 50, 0, 2, 71, 0, 30, 0, 2, 2, 1], [7, 0, 2, 9, 91, 0, 2, 70, 1, 0, 0, 0, 0, 0], [7, 1, 2, 9, 74, 0, 0, 76, 0, 0, 0, 0, 0, 0], [16, 0, 2, 13, 45, 0, 0, 56, 0, 16, 1, 0, 0, 0], [20, 0, 2, 7, 90, 0, 2, 65, 0, 0, 0, 0, 0, 0], [30, 0, 3, 21, 115, 0, 0, 21, 0, 19, 1, 2, 0, 0], [17, 0, 2, 21, 79, 0, 2, 47, 0, 5, 0, 0, 0, 0], [12, 0, 1, 5, 30, 0, 0, 70, 0, 0, 0, 0, 0, 0], [21, 1, 3, 27, 43, 0, 0, 11, 1, 37, 2, 0, 2, 1], [11, 1, 1, 19, 120, 0, 2, 68, 0, 0, 0, 0, 0, 0], [22, 1, 0, 13, 21, 0, 2, 60, 0, 18, 1, 0, 2, 0], [32, 0, 3, 43, 54, 1, 0, 63, 1, 10, 1, 2, 2, 1], [4, 1, 0, 13, 57, 0, 0, 79, 1, 34, 1, 0, 2, 1], [28, 0, 3, 33, 68, 0, 0, 52, 1, 14, 1, 0, 0, 1], [21, 1, 1, 21, 85, 0, 0, 53, 0, 0, 0, 0, 0, 0], [24, 1, 3, 19, 82, 0, 2, 29, 1, 28, 1, 2, 2, 1], [9, 1, 3, 8, 37, 0, 0, 59, 0, 0, 0, 0, 2, 0], [30, 0, 3, 44, 128, 0, 0, 52, 1, 0, 0, 0, 0, 0], [16, 0, 3, 8, 77, 0, 2, 57, 0, 0, 0, 0, 0, 0], [19, 1, 2, 21, 24, 1, 2, 50, 0, 12, 2, 0, 0, 0], [11, 0, 3, 26, 62, 0, 2, 50, 1, 2, 1, 0, 0, 0], [31, 1, 0, 26, 101, 1, 2, 72, 0, 14, 1, 1, 0, 1], [35, 1, 0, 38, 60, 1, 2, 30, 0, 1, 1, 1, 0, 0], [35, 1, 2, 27, 77, 0, 2, 44, 0, 19, 1, 3, 2, 1], [33, 1, 3, 1, 112, 0, 2, 24, 1, 9, 1, 2, 0, 1], [34, 0, 2, 13, 37, 0, 2, 15, 0, 15, 1, 0, 0, 0], [1, 1, 0, 12, 14, 0, 2, 72, 0, 0, 0, 0, 0, 0], [28, 0, 3, 26, 109, 1, 0, 8, 0, 18, 1, 3, 0, 1], [17, 1, 3, 27, 111, 0, 0, 21, 1, 36, 1, 3, 2, 1], [12, 1, 2, 33, 57, 0, 0, 45, 0, 33, 1, 0, 0, 1], [33, 1, 3, 17, 77, 1, 0, 61, 0, 2, 1, 2, 2, 1], [16, 1, 2, 20, 23, 0, 0, 61, 0, 0, 0, 0, 0, 0], [8, 1, 2, 13, 65, 1, 0, 87, 0, 8, 2, 0, 2, 0], [22, 0, 3, 23, 140, 0, 2, 48, 1, 18, 1, 2, 2, 1], [7, 1, 3, 8, 8, 0, 2, 56, 0, 0, 0, 0, 2, 1], [8, 0, 3, 3, 88, 0, 2, 21, 0, 6, 1, 0, 0, 0], [19, 1, 2, 21, 70, 1, 2, 71, 0, 0, 0, 3, 0, 0], [9, 1, 2, 21, 124, 0, 0, 60, 0, 18, 0, 1, 0, 0], [22, 1, 3, 22, 16, 0, 2, 7, 1, 20, 1, 1, 1, 1], [18, 1, 3, 7, 59, 1, 0, 45, 0, 1, 0, 3, 2, 0], [28, 0, 3, 27, 138, 0, 2, 55, 0, 12, 1, 0, 0, 0], [36, 1, 2, 38, 92, 0, 0, 12, 1, 27, 1, 1, 2, 1], [20, 1, 3, 27, 64, 0, 0, 58, 0, 12, 0, 0, 0, 0], [36, 1, 3, 30, 9, 0, 0, 24, 1, 25, 2, 0, 2, 1], [20, 1, 1, 7, 121, 0, 0, 54, 0, 0, 0, 0, 2, 0], [2, 1, 3, 18, 101, 0, 2, 54, 1, 0, 0, 0, 2, 1], [14, 1, 2, 16, 78, 1, 0, 73, 0, 0, 0, 2, 0, 0], [21, 0, 1, 24, 74, 0, 2, 59, 0, 14, 1, 0, 0, 0], [24, 0, 3, 1, 72, 0, 2, 21, 0, 10, 1, 0, 0, 0], [20, 0, 2, 8, 40, 0, 0, 56, 0, 16, 1, 0, 0, 0], [35, 0, 0, 27, 64, 0, 0, 49, 0, 17, 0, 2, 0, 0], [40, 1, 3, 17, 116, 0, 2, 60, 1, 0, 0, 3, 0, 1], [34, 1, 2, 12, 99, 0, 0, 49, 0, 10, 0, 1, 2, 0], [24, 1, 3, 17, 113, 0, 2, 69, 0, 0, 0, 2, 2, 1], [26, 1, 3, 17, 81, 0, 2, 39, 1, 26, 1, 1, 2, 1], [17, 1, 3, 27, 112, 0, 0, 71, 1, 16, 0, 0, 2, 1], [21, 1, 3, 38, 106, 0, 2, 43, 1, 8, 1, 1, 2, 1], [18, 1, 0, 34, 111, 1, 0, 75, 0, 12, 1, 0, 2, 0], [26, 0, 2, 3, 125, 0, 0, 58, 0, 0, 0, 1, 0, 0], [24, 1, 2, 5, 65, 0, 2, 52, 1, 6, 1, 0, 2, 0], [30, 1, 2, 17, 121, 0, 0, 30, 1, 17, 1, 0, 2, 1], [3, 1, 2, 21, 74, 0, 0, 83, 0, 32, 2, 0, 0, 0], [25, 1, 0, 40, 105, 0, 2, 57, 0, 2, 1, 0, 2, 1], [17, 1, 2, 17, 69, 1, 2, 64, 0, 23, 1, 0, 0, 0], [9, 0, 2, 14, 39, 0, 0, 63, 0, 2, 1, 0, 0, 0], [24, 1, 3, 19, 42, 0, 2, 30, 1, 21, 1, 3, 2, 1], [0, 1, 1, 21, 30, 0, 2, 89, 0, 0, 0, 0, 0, 0], [7, 0, 1, 21, 30, 0, 2, 70, 0, 14, 0, 0, 0, 0], [29, 0, 2, 24, 75, 0, 2, 70, 0, 0, 0, 0, 0, 0], [17, 1, 2, 0, 53, 0, 0, 52, 1, 0, 0, 1, 2, 0], [20, 1, 2, 13, 81, 0, 2, 45, 0, 4, 1, 0, 2, 0], [10, 1, 1, 13, 46, 0, 0, 68, 0, 0, 0, 0, 0, 0], [20, 1, 3, 8, 64, 0, 0, 25, 1, 26, 1, 1, 2, 1], [31, 1, 3, 24, 77, 0, 2, 26, 0, 26, 1, 1, 2, 1], [23, 1, 2, 33, 7, 0, 0, 72, 0, 16, 0, 0, 0, 0], [29, 1, 3, 21, 131, 1, 2, 31, 1, 17, 0, 3, 2, 1], [2, 0, 3, 26, 15, 0, 0, 79, 0, 14, 0, 0, 0, 0], [7, 1, 1, 24, 29, 0, 0, 31, 0, 0, 1, 0, 1, 0], [28, 0, 2, 21, 86, 0, 0, 4, 0, 12, 1, 1, 2, 1], [9, 0, 3, 22, 134, 1, 2, 34, 1, 28, 1, 0, 2, 1], [24, 0, 0, 33, 102, 1, 2, 60, 0, 10, 0, 0, 0, 0], [18, 1, 0, 12, 18, 0, 2, 85, 0, 0, 1, 0, 1, 0], [27, 0, 3, 30, 119, 0, 2, 44, 1, 10, 1, 0, 2, 1], [5, 1, 3, 12, 45, 0, 0, 38, 0, 12, 1, 0, 2, 1], [11, 1, 3, 10, 83, 0, 2, 81, 0, 0, 0, 0, 0, 0], [18, 1, 3, 19, 78, 0, 0, 59, 1, 0, 0, 1, 2, 1], [28, 1, 2, 21, 57, 0, 0, 44, 0, 17, 1, 3, 2, 0], [28, 0, 3, 38, 4, 0, 2, 43, 0, 38, 2, 3, 2, 1], [19, 0, 3, 26, 60, 0, 2, 58, 0, 0, 0, 0, 0, 0], [9, 1, 3, 13, 11, 0, 2, 19, 1, 24, 1, 0, 2, 1], [13, 1, 2, 26, 80, 0, 2, 54, 0, 0, 0, 0, 0, 0], [18, 1, 1, 13, 128, 0, 0, 70, 0, 2, 0, 0, 0, 0], [34, 1, 2, 44, 96, 1, 2, 48, 1, 16, 1, 0, 2, 1], [5, 1, 2, 27, 127, 0, 2, 79, 0, 0, 0, 0, 0, 0], [19, 0, 3, 21, 87, 0, 2, 41, 0, 4, 1, 0, 0, 0], [28, 0, 3, 27, 91, 0, 2, 58, 0, 33, 2, 2, 0, 1], [17, 0, 2, 27, 120, 0, 2, 40, 0, 15, 0, 1, 0, 0], [26, 1, 3, 21, 76, 0, 0, 42, 1, 14, 0, 1, 2, 1], [31, 1, 3, 8, 72, 0, 2, 56, 0, 6, 0, 2, 1, 1], [31, 0, 2, 35, 92, 0, 0, 46, 0, 8, 0, 0, 0, 0], [26, 1, 2, 27, 17, 0, 2, 53, 0, 28, 1, 0, 0, 1], [26, 1, 3, 30, 101, 0, 2, 40, 1, 26, 1, 2, 2, 1], [20, 1, 3, 13, 19, 0, 0, 13, 0, 14, 1, 1, 2, 1], [10, 1, 1, 21, 45, 0, 2, 84, 0, 0, 0, 0, 0, 0], [10, 1, 3, 9, 107, 0, 2, 51, 0, 0, 0, 1, 0, 1], [17, 1, 2, 8, 10, 0, 0, 22, 0, 6, 0, 0, 0, 0], [25, 1, 2, 33, 38, 1, 0, 55, 0, 16, 0, 0, 0, 0], [37, 0, 1, 38, 114, 0, 0, 60, 0, 4, 0, 2, 0, 0], [27, 1, 2, 33, 67, 1, 0, 35, 1, 10, 1, 0, 0, 0], [21, 1, 3, 22, 135, 0, 0, 31, 1, 12, 1, 1, 2, 1], [30, 1, 2, 27, 132, 0, 0, 56, 0, 0, 0, 0, 0, 1], [9, 1, 3, 33, 71, 0, 0, 69, 0, 15, 0, 0, 0, 0], [24, 0, 2, 13, 133, 0, 0, 70, 0, 0, 0, 0, 0, 0], [26, 1, 3, 21, 32, 0, 2, 31, 1, 23, 1, 2, 2, 1], [24, 1, 1, 13, 103, 0, 2, 58, 0, 17, 1, 0, 0, 1], [15, 1, 1, 21, 89, 0, 0, 69, 0, 6, 0, 0, 0, 0], [14, 1, 1, 8, 55, 0, 0, 66, 0, 10, 2, 0, 2, 1], [18, 1, 2, 41, 26, 1, 0, 60, 0, 5, 0, 0, 2, 0], [10, 1, 1, 13, 86, 0, 0, 71, 0, 0, 0, 0, 2, 0], [22, 0, 1, 27, 109, 0, 2, 51, 0, 13, 1, 0, 0, 0], [23, 1, 3, 27, 20, 0, 0, 46, 0, 4, 1, 0, 1, 0], [33, 1, 3, 38, 104, 0, 2, 9, 1, 15, 1, 3, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "list_temp=a_list_enc\n",
    "\n",
    "disc =KBinsDiscretizer(n_bins=4,encode='ordinal', strategy='uniform')\n",
    "disc.fit_transform(list_temp)\n",
    "\n",
    "a_list_enc_disc = list_temp\n",
    "\n",
    "print(a_list_enc_disc)\n",
    "\n",
    "df=pd.DataFrame(data=a_list_enc_disc)\n",
    "df.to_csv('a_list_enc_disc.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=[]\n",
    "Y_data=[]\n",
    "\n",
    "for i in range(len(a_list_enc_disc)):\n",
    "    X_data.append(list(a_list_enc_disc[i][:-1]))\n",
    "    Y_data.append(a_list_enc_disc[i][-1])\n",
    "    \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.3, random_state=42)\n",
    "\n",
    "no_of_node = []\n",
    "accuracy = []\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=42)\n",
    "clf.fit(X_train_std,Y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "print(accuracy_score(Y_test, y_pred))\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion='gini',max_depth=3, random_state=42)\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "print(accuracy_score(Y_test, y_pred))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-85-5635924d0108>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-5635924d0108>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    togradata = tree.export_graphviz(clf,out_file=None, filled=True,rounded=True, sp)\u001b[0m\n\u001b[0m                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "#6-2\n",
    "import graphviz\n",
    "\n",
    "togradata = tree.export_graphviz(clf,out_file=None, filled=True,rounded=True, sp)\n",
    "graph =praphviz.Source(togradata)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
